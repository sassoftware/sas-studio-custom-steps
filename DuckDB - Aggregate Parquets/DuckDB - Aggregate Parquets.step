{"creationTimeStamp":"2025-12-16T16:10:33.724357Z","createdBy":"Sundaresh.Sankaran@sas.com","modifiedTimeStamp":"2025-12-16T16:10:33.724357Z","modifiedBy":"Sundaresh.Sankaran@sas.com","name":"DuckDB - Aggregate Parquets.step","displayName":"DuckDB - Aggregate Parquets.step","localDisplayName":"DuckDB - Aggregate Parquets.step","links":[{"method":"GET","rel":"self","href":"/dataFlows/steps/1b33dfa8-0521-4eb0-9eec-b83501c0206d","uri":"/dataFlows/steps/1b33dfa8-0521-4eb0-9eec-b83501c0206d","type":"application/vnd.sas.data.flow.step"},{"method":"GET","rel":"alternate","href":"/dataFlows/steps/1b33dfa8-0521-4eb0-9eec-b83501c0206d","uri":"/dataFlows/steps/1b33dfa8-0521-4eb0-9eec-b83501c0206d","type":"application/vnd.sas.data.flow.step.summary"},{"method":"GET","rel":"up","href":"/dataFlows/steps","uri":"/dataFlows/steps","type":"application/vnd.sas.collection","itemType":"application/vnd.sas.data.flow.step.summary"},{"method":"PUT","rel":"update","href":"/dataFlows/steps/1b33dfa8-0521-4eb0-9eec-b83501c0206d","uri":"/dataFlows/steps/1b33dfa8-0521-4eb0-9eec-b83501c0206d","type":"application/vnd.sas.data.flow.step","responseType":"application/vnd.sas.data.flow.step"},{"method":"DELETE","rel":"delete","href":"/dataFlows/steps/1b33dfa8-0521-4eb0-9eec-b83501c0206d","uri":"/dataFlows/steps/1b33dfa8-0521-4eb0-9eec-b83501c0206d"},{"method":"POST","rel":"copy","href":"/dataFlows/steps/1b33dfa8-0521-4eb0-9eec-b83501c0206d/copy","uri":"/dataFlows/steps/1b33dfa8-0521-4eb0-9eec-b83501c0206d/copy","responseType":"application/vnd.sas.data.flow.step"},{"method":"GET","rel":"transferExport","href":"/dataFlows/steps/1b33dfa8-0521-4eb0-9eec-b83501c0206d","uri":"/dataFlows/steps/1b33dfa8-0521-4eb0-9eec-b83501c0206d","responseType":"application/vnd.sas.transfer.object"},{"method":"PUT","rel":"transferImportUpdate","href":"/dataFlows/steps/1b33dfa8-0521-4eb0-9eec-b83501c0206d","uri":"/dataFlows/steps/1b33dfa8-0521-4eb0-9eec-b83501c0206d","type":"application/vnd.sas.transfer.object","responseType":"application/vnd.sas.summary"}],"metadataVersion":1,"version":2,"type":"code","flowMetadata":{"outputPorts":[{"name":"output_table","displayName":"output_table","localDisplayName":"output_table","minEntries":1,"maxEntries":1,"defaultEntries":0,"type":"table"}]},"ui":"{\"showPageContentOnly\": true, \"pages\": [{\"id\": \"params\", \"type\": \"page\", \"label\": \"Parameters\", \"children\": [{\"id\": \"section_input_params\", \"type\": \"section\", \"label\": \"Input Parameters\", \"open\": true, \"children\": [{\"id\": \"parquet_file_path\", \"type\": \"path\", \"label\": \"Enter path to parquet file:\", \"pathtype\": \"file\", \"placeholder\": \"\", \"required\": true, \"visible\": \"\"}, {\"id\": \"function_name\", \"type\": \"list\", \"items\": [{\"value\": \"AVG\"}, {\"value\": \"COUNT\"}, {\"value\": \"MEDIAN\"}, {\"value\": \"MODE\"}, {\"value\": \"MIN\"}, {\"value\": \"MAX\"}, {\"value\": \"MAD\"}, {\"value\": \"SUM\"}, {\"value\": \"STDDEV\"}, {\"value\": \"STDDEV_POP\"}, {\"value\": \"VAR_SAMP\"}, {\"value\": \"VAR_POP\"}], \"label\": \"Select required aggregation functions:\", \"max\": null, \"min\": null, \"visible\": \"\"}, {\"id\": \"agg_columns\", \"type\": \"textfield\", \"label\": \"List columns to aggregate (space separated):\", \"placeholder\": \"DELINQ DEBTINC\", \"required\": true}, {\"id\": \"group_by_columns\", \"type\": \"textfield\", \"label\": \"List Group-by columns (optional):\", \"placeholder\": \"\", \"required\": false}, {\"id\": \"output_table\", \"type\": \"outputtable\", \"label\": \"Output table (preferably a data set backed by a DuckDB lib name)\", \"required\": true, \"placeholder\": \"\", \"visible\": \"\"}]}]}, {\"id\": \"about\", \"type\": \"page\", \"label\": \"About\", \"children\": [{\"id\": \"section_about_intro\", \"type\": \"section\", \"label\": \"DuckDB - Aggregate Parquets\", \"open\": true, \"visible\": \"\", \"children\": [{\"id\": \"section_about_intro_text\", \"type\": \"text\", \"text\": \"This custom step dynamically builds a DuckDB SQL aggregation query on parquet file formats and pushes it down to DuckDB through the SAS/ACCESS Interface to DuckDB.\\n\\nOpen file formats such as Parquet are popular due to the benefits they offer in reduced data footprint and columnar structure.  Also, DuckDB has gained popularity as a performant query processing engine which reduces data movement.  Presently, the benefits of DuckDB are better realised if the query is pushed down through explicit passthrough.  This custom step helps users conveniently run multiple aggregation queries without having to explicitly write SQL in the DuckDB dialect.\", \"visible\": \"\"}, {\"id\": \"section_about_parameters\", \"type\": \"section\", \"label\": \"Parameters\", \"open\": false, \"visible\": \"\", \"children\": [{\"id\": \"section_about_parameters_input\", \"type\": \"section\", \"label\": \"Input Parameters\", \"open\": false, \"children\": [{\"id\": \"section_about_parameters_input_text\", \"type\": \"text\", \"text\": \"1. Path to parquet file(file selector, required): select only files on the SAS server (i.e. the filesystem)\\n2. Select Aggregation functions (list, required): select one or more functions to aggregate by.  This list shall expand in future.\\n3. List columns to aggregate (text field, required): list your columns in a space separated format.  This step does not provide a column selector as it queries directly from parquet.\\n4. List Group-by columns (text field, optional): list any columns which you like to group your aggregations by. \", \"visible\": \"\"}]}, {\"id\": \"section_about_parameters_output\", \"type\": \"section\", \"label\": \"Output parameters\", \"open\": true, \"visible\": \"\", \"children\": [{\"id\": \"section_about_parameters_output_text\", \"type\": \"text\", \"text\": \"-Output table (output port, required): select an output table.  Choose based on your use case, but it's preferred that this belongs to a DuckDB lib name. \", \"visible\": \"\"}]}]}, {\"id\": \"section_about_version\", \"type\": \"section\", \"label\": \"About this step\", \"open\": true, \"children\": [{\"id\": \"version_text\", \"type\": \"text\", \"text\": \"Version: 1.1.4 (15DEC2025)\\nContact: Sundaresh Sankaran (Sundaresh.sankaran@sas.com)\"}]}]}]}], \"syntaxversion\": \"1.3.0\", \"values\": {\"parquet_file_path\": \"\", \"function_name\": [], \"agg_columns\": \"DELINQ DEBTINC\", \"group_by_columns\": \"\", \"output_table\": {\"library\": \"\", \"table\": \"\"}}}","localUi":"{\"pages\":[{\"children\":[{\"children\":[{\"id\":\"parquet_file_path\",\"label\":\"Enter path to parquet file:\",\"pathtype\":\"file\",\"placeholder\":\"\",\"required\":true,\"type\":\"path\",\"visible\":\"\"},{\"id\":\"function_name\",\"items\":[{\"value\":\"AVG\"},{\"value\":\"COUNT\"},{\"value\":\"MEDIAN\"},{\"value\":\"MODE\"},{\"value\":\"MIN\"},{\"value\":\"MAX\"},{\"value\":\"MAD\"},{\"value\":\"SUM\"},{\"value\":\"STDDEV\"},{\"value\":\"STDDEV_POP\"},{\"value\":\"VAR_SAMP\"},{\"value\":\"VAR_POP\"}],\"label\":\"Select required aggregation functions:\",\"max\":null,\"min\":null,\"type\":\"list\",\"visible\":\"\"},{\"id\":\"agg_columns\",\"label\":\"List columns to aggregate (space separated):\",\"placeholder\":\"DELINQ DEBTINC\",\"required\":true,\"type\":\"textfield\"},{\"id\":\"group_by_columns\",\"label\":\"List Group-by columns (optional):\",\"placeholder\":\"\",\"required\":false,\"type\":\"textfield\"},{\"id\":\"output_table\",\"label\":\"Output table (preferably a data set backed by a DuckDB lib name)\",\"placeholder\":\"\",\"required\":true,\"type\":\"outputtable\",\"visible\":\"\"}],\"id\":\"section_input_params\",\"label\":\"Input Parameters\",\"open\":true,\"type\":\"section\"}],\"id\":\"params\",\"label\":\"Parameters\",\"type\":\"page\"},{\"children\":[{\"children\":[{\"id\":\"section_about_intro_text\",\"text\":\"This custom step dynamically builds a DuckDB SQL aggregation query on parquet file formats and pushes it down to DuckDB through the SAS/ACCESS Interface to DuckDB.\\n\\nOpen file formats such as Parquet are popular due to the benefits they offer in reduced data footprint and columnar structure.  Also, DuckDB has gained popularity as a performant query processing engine which reduces data movement.  Presently, the benefits of DuckDB are better realised if the query is pushed down through explicit passthrough.  This custom step helps users conveniently run multiple aggregation queries without having to explicitly write SQL in the DuckDB dialect.\",\"type\":\"text\",\"visible\":\"\"},{\"children\":[{\"children\":[{\"id\":\"section_about_parameters_input_text\",\"text\":\"1. Path to parquet file(file selector, required): select only files on the SAS server (i.e. the filesystem)\\n2. Select Aggregation functions (list, required): select one or more functions to aggregate by.  This list shall expand in future.\\n3. List columns to aggregate (text field, required): list your columns in a space separated format.  This step does not provide a column selector as it queries directly from parquet.\\n4. List Group-by columns (text field, optional): list any columns which you like to group your aggregations by. \",\"type\":\"text\",\"visible\":\"\"}],\"id\":\"section_about_parameters_input\",\"label\":\"Input Parameters\",\"open\":false,\"type\":\"section\"},{\"children\":[{\"id\":\"section_about_parameters_output_text\",\"text\":\"-Output table (output port, required): select an output table.  Choose based on your use case, but it's preferred that this belongs to a DuckDB lib name. \",\"type\":\"text\",\"visible\":\"\"}],\"id\":\"section_about_parameters_output\",\"label\":\"Output parameters\",\"open\":true,\"type\":\"section\",\"visible\":\"\"}],\"id\":\"section_about_parameters\",\"label\":\"Parameters\",\"open\":false,\"type\":\"section\",\"visible\":\"\"},{\"children\":[{\"id\":\"version_text\",\"text\":\"Version: 1.1.4 (15DEC2025)\\nContact: Sundaresh Sankaran (Sundaresh.sankaran@sas.com)\",\"type\":\"text\"}],\"id\":\"section_about_version\",\"label\":\"About this step\",\"open\":true,\"type\":\"section\"}],\"id\":\"section_about_intro\",\"label\":\"DuckDB - Aggregate Parquets\",\"open\":true,\"type\":\"section\",\"visible\":\"\"}],\"id\":\"about\",\"label\":\"About\",\"type\":\"page\"}],\"showPageContentOnly\":true,\"syntaxversion\":\"1.3.0\",\"values\":{\"agg_columns\":\"DELINQ DEBTINC\",\"function_name\":[],\"group_by_columns\":\"\",\"output_table\":{\"library\":\"\",\"table\":\"\"},\"parquet_file_path\":\"\"}}","templates":{"SAS":"/* SAS templated code goes here */\n\n/* -------------------------------------------------------------------------------------------*\n   DuckDB - Aggregate Parquets - Version 1.1.4\n\n   This program dynamically builds a DuckDB SQL aggregation query and\n   pushes it down to Duck DB through the SAS/ACCESS Interface to Duck DB.\n   \n   This version refactored to follow the structural patterns, macro usage and\n   verbose commenting style used by the \"LLM - Azure OpenAI In-context Learning.sas\"\n   program while preserving the original purpose and logic.\n\n   Author: Sundaresh Sankaran (original)\n   Refactor: Polished after AI-assisted automation\n   Version: 1.1.4 (2025-12-15)\n*-------------------------------------------------------------------------------------------- */\n\n/* -------------------------------------------------------------------------------------------*\n    User Parameters\n    \n    The parameters below allow customization of the aggregation operation,\n    including the input file path, aggregation functions, columns to aggregate,\n    grouping columns, and output table.\n    \n    Users can modify these parameters to suit their specific data and analysis needs.\n* -------------------------------------------------------------------------------------------- */\n\n/*  Directory or prefix containing parquet files  */\n/* %let parquet_file_path=sasserver:/mnt/viya-share/data/parquet-test/ss-new/parquet-test/HMEQ_WITH_CUST.parquet; */\n\n \n\n/* Aggregation function list: define count then each function name macro */\n/* %let function_name_count=4; */\n/* %let function_name_1=AVG; */\n/* %let function_name_2=SUM; */\n/* %let function_name_3=STDDEV; */\n/* %let function_name_4=COUNT; */\n\n/* Comma-separated list of columns to aggregate and group-by columns (space or comma separated OK)  */\n/* %let agg_columns=DELINQ DEBTINC;                    */\n/* %let group_by_columns= ;                  */\n\n/*  Output table assigned to the Duck DB engine. Provide libname-qualified name if desired.  */\n/* %let output_table=dukonce.TABLE_NUM_AGGS_DD; */\n\n\n/* -----------------------------------------------------------------------------------------*\n   Macros\n\n   The macros below follow the structural conventions used in the LLM-Azure example:\n\n   - small utility macros for runtime triggers and error flags\n   - a focused macro to build SQL strings and one to execute the Duck DB query\n*------------------------------------------------------------------------------------------*/\n\n/* -------------------------------------------------------------------------------------------* \n   Macro to initialize a run-time trigger global macro variable to run SAS Studio Custom Steps. \n   A value of 1 (the default) enables this custom step to run.  A value of 0 (provided by \n   upstream code) sets this to disabled.\n\n   Input:\n   1. triggerName: The name of the runtime trigger you wish to create. Ensure you provide a \n      unique value to this parameter since it will be declared as a global variable.\n\n   Output:\n   2. &triggerName : A global variable which takes the name provided to triggerName.\n*-------------------------------------------------------------------------------------------- */\n\n%macro _create_runtime_trigger(triggerName);\n   %global &triggerName.;\n   %if %sysevalf(%superq(&triggerName.)=, boolean)  %then %do;\n      %put NOTE: Trigger macro variable &triggerName. does not exist. Creating it now.;\n      %let &triggerName.=1;\n   %end;\n%mend _create_runtime_trigger;\n\n\n/* -----------------------------------------------------------------------------------------* \n   Macro to create an error flag for capture during code execution.\n\n   Input:\n      1. errorFlagName: The name of the error flag you wish to create. Ensure you provide a \n         unique value to this parameter since it will be declared as a global variable.\n      2. errorFlagDesc: A description to add to the error flag.\n\n    Output:\n      1. &errorFlagName : A global variable which takes the name provided to errorFlagName.\n      2. &errorFlagDesc : A global variable which takes the name provided to errorFlagDesc.\n*------------------------------------------------------------------------------------------ */\n\n%macro _create_error_flag(errorFlagName, errorFlagDesc);\n\n   %global &errorFlagName.;\n   %let &errorFlagName.=0;\n   %global &errorFlagDesc.;\n\n%mend _create_error_flag;\n\n\n/* -----------------------------------------------------------------------------------------* \n  Macro: _create_sql_string\n  Purpose: Build the comma-separated list of aggregate expressions and the\n           group-by column list suitable for injection into the DuckDB SQL.\n  Behavior: Does not execute SQL; only constructs macro variables:\n            - &final_agg_columns.  (aggregations with aliases)\n            - &final_group_by_columns. (comma-separated grouping columns)\n*------------------------------------------------------------------------------------------ */\n\n%macro _create_sql_string;\n\n    %global final_agg_columns final_group_by_columns group_by_clause;\n    %local i function_name;\n    %let final_agg_columns=;\n\n    %do i = 1 %to &function_name_count.;\n\n        %let function_name = &&function_name_&i.;\n\n        data _null_;\n        length new $32767.;\n        /* Surrounding double-quotes let the macro variable &function_name insert into the pattern */\n        new = prxchange('s/\\s+/,/i', -1, trim(\"&agg_columns.\"));\n        new = prxchange(\"s/\\b\\w+\\b/&function_name.($0) AS &function_name._$0/i\", -1, new );       \n        call symput(\"new_agg_columns_&i.\", trim(new));\n        run;\n\n        %if &i = 1 %then %do;\n            %let final_agg_columns=&&new_agg_columns_&i..;\n        %end;\n        %else %do;\n            %let final_agg_columns=&final_agg_columns., &&new_agg_columns_&i..;\n        %end;\n\n    %end;\n\n\n\n/* Create GROUP BY clause only if group-by columns are provided */\n    %if \"&group_by_columns.\" = \"\" %then %do;\n      %let final_group_by_columns=;\n      %let group_by_clause=;\n    %end;\n    %else %do;\n    /* Convert whitespace-separated group-by columns to comma-separated list */\n         data _null_;\n            new = prxchange('s/\\s+/,/i', -1, \"&group_by_columns.\");\n            call symput('final_group_by_columns', new);\n         run;\n        %let group_by_clause=group by &final_group_by_columns.;\n        %let final_group_by_columns=&final_group_by_columns.,;\n    %end;\n    \n%mend _create_sql_string;\n\n\n/* -----------------------------------------------------------------------------------------* \n   Macro to identify whether a given folder location provided from a \n   SAS Studio Custom Step folder selector happens to be a SAS Content folder\n   or a folder on the filesystem (SAS Server).\n\n   Input:\n   1. pathReference: A path reference provided by the file or folder selector control in \n      a SAS Studio Custom step.\n\n   Output:\n   1. _path_identifier: Set inside macro, a global variable indicating the prefix of the \n      path provided.\n\n   Also available at: https://raw.githubusercontent.com/SundareshSankaran/sas_utility_programs/main/code/Identify%20SAS%20Content%20or%20Server/macro_identify_sas_content_server.sas\n\n*------------------------------------------------------------------------------------------ */\n\n%macro _identify_content_or_server(pathReference);\n   %global _path_identifier;\n   data _null_;\n      call symput(\"_path_identifier\", scan(\"&pathReference.\",1,\":\",\"MO\"));\n   run;\n   %put NOTE: _path_identifier is &_path_identifier. ;\n%mend _identify_content_or_server;\n\n/* -----------------------------------------------------------------------------------------* \n   Macro to extract the path provided from a SAS Studio Custom Step file or folder selector.\n\n   Input:\n   1. pathReference: A path reference provided by the file or folder selector control in \n      a SAS Studio Custom step.\n\n   Output:\n   1. _sas_folder_path: Set inside macro, a global variable containing the path.\n\n   Also available at: https://raw.githubusercontent.com/SundareshSankaran/sas_utility_programs/main/code/Extract%20SAS%20Folder%20Path/macro_extract_sas_folder_path.sas\n\n*------------------------------------------------------------------------------------------ */\n\n%macro _extract_sas_folder_path(pathReference);\n\n   %global _sas_folder_path;\n\n   data _null_;\n      call symput(\"_sas_folder_path\", scan(\"&pathReference.\",2,\":\",\"MO\"));\n   run;\n\n%mend _extract_sas_folder_path;\n\n\n/* -----------------------------------------------------------------------------------------* \n  Macro: _duckdb_execute_aggregations\n  Purpose: Build the SQL (via create_sql_string) and run a direct connection\n           to the Duck DB engine, executing the aggregation and returning\n           the results from the pushed-down query.\n*------------------------------------------------------------------------------------------ */\n\n%macro _duckdb_execute_aggregations;\n\n   %if &_duckdb_error_flag. = 0 %then %do;\n      libname dukonce sasioduk;\n   %end;\n\n   %if &_duckdb_error_flag. = 0 %then %do;\n      %_identify_content_or_server(&parquet_file_path.);\n\n      %if \"&_path_identifier.\"=\"sasserver\" %then %do;\n         %put NOTE: Folder location prefixed with &_path_identifier. is on the SAS Server.;\n      %end;\n\n      %else %do;\n\n         %let _duckdb_error_flag=1;\n         %put ERROR: Please select a valid file on the SAS Server (filesystem) containing your Azure OpenAI key.  Key should be in a secure location within filesystem. ;\n         data _null_;\n            call symputx(\"_duckdb_error_desc\", \"Please select a valid file on the SAS Server (filesystem) containing your Azure OpenAI key.  Key should be in a secure location within filesystem.\");\n         run;\n      \n      %end;\n   %end;\n\n   %if &_duckdb_error_flag. = 0 %then %do;\n\n      %_extract_sas_folder_path(&parquet_file_path.);\n\n      %if \"&_sas_folder_path.\" = \"\" %then %do;\n\n         %let _duckdb_error_flag = 1;\n         %let _duckdb_error_desc = The field is empty, please select a valid path  ;\n         %put ERROR: &_duckdb_error_desc. ;\n\n      %end;\n      %else %do;\n         %let file_path=&_sas_folder_path.;\n         %put NOTE: Extracted file path is &file_path.;\n      %end;\n   %end;\n\n\n   %if &_duckdb_error_flag. = 0 %then %do;\n        %put NOTE: Building SQL aggregation strings...;\n        %_create_sql_string;\n   %end;\n\n   %put NOTE: Final string resolves to &final_agg_columns.;\n   %put NOTE: Final group by columns resolve to &final_group_by_columns.;\n\n   %if &_duckdb_error_flag. = 0 %then %do;\n        %put NOTE: Executing DuckDB aggregation query...;\n        proc sql;\n            connect using dukonce;\n            select * from connection to dukonce(\n                select \n                &final_group_by_columns.\n                &final_agg_columns.\n                from read_parquet(\"&file_path.\")\n                &group_by_clause.\n            );\n        quit;\n   %end;\n   %else %do;\n        %let _duckdb_error_desc = Cannot execute DuckDB aggregation query.; \n        %put ERROR: &_duckdb_error_desc.;\n   %end;\n\n%mend _duckdb_execute_aggregations;\n\n\n/* -----------------------------------------------------------------------------------------* \n  Execution Control\n*------------------------------------------------------------------------------------------ */\n\n%_create_error_flag(_duckdb_error_flag, _duckdb_error_desc);\n%_create_runtime_trigger(_duckdb_run_trigger);\n\n%put NOTE: Starting duckdb aggregations program (v1.1.4)...;\n%put NOTE: Run trigger value is &_duckdb_run_trigger.;\n\n%if &_duckdb_run_trigger. = 1 %then %do;\n   %_duckdb_execute_aggregations;\n%end;\n\n%if &_duckdb_run_trigger. = 0 %then %do;\n   %put NOTE: This step has been disabled. Nothing to do.;\n%end;\n\n\n/* ----------------------------------------------------------------------------------* \n    Cleanup \n*------------------------------------------------------------------------------------------ */\n\n%if %symexist(final_agg_columns) %then %do;\n   %symdel final_agg_columns;\n%end;\n\n%if %symexist(final_group_by_columns) %then %do;\n   %symdel final_group_by_columns;\n%end;\n\n%if %symexist(group_by_clause) %then %do;\n   %symdel group_by_clause;\n%end;\n\n%if %symexist(_duckdb_run_trigger) %then %do;\n   %symdel _duckdb_run_trigger;\n%end;\n\n%if %symexist(_duckdb_run_trigger) %then %do;\n   %symdel _duckdb_run_trigger;\n%end;\n\n%if %symexist(_duckdb_run_trigger) %then %do;\n   %symdel _duckdb_run_trigger;\n%end;\n\n%if %symexist(_duckdb_error_flag) %then %do;\n   %symdel _duckdb_error_flag;\n%end;\n\n%if %symexist(_duckdb_error_desc) %then %do;\n   %symdel _duckdb_error_desc;\n%end;\n\n/* Remove helper macros from global symbol table */\n%sysmacdelete _create_runtime_trigger;\n%sysmacdelete _create_error_flag;\n%sysmacdelete _create_sql_string;\n%sysmacdelete _duckdb_execute_aggregations;\n\n%put NOTE: duckdb aggregations program (v1.1.4) completed.;"},"eTag":"W/\"1765901433724357000\""}