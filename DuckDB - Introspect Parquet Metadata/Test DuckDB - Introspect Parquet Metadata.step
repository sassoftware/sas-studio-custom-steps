{"creationTimeStamp":"2026-02-05T04:44:21.738804Z","createdBy":"sinsrn","modifiedTimeStamp":"2026-02-05T04:45:00.724871Z","modifiedBy":"sinsrn","id":"39cb65bf-d464-41c0-bd16-49d48461ef36","name":"Test DuckDB - Introspect Parquet Metadata.step","displayName":"Test DuckDB - Introspect Parquet Metadata.step","localDisplayName":"Test DuckDB - Introspect Parquet Metadata.step","links":[{"method":"GET","rel":"self","href":"/dataFlows/steps/39cb65bf-d464-41c0-bd16-49d48461ef36","uri":"/dataFlows/steps/39cb65bf-d464-41c0-bd16-49d48461ef36","type":"application/vnd.sas.data.flow.step"},{"method":"GET","rel":"alternate","href":"/dataFlows/steps/39cb65bf-d464-41c0-bd16-49d48461ef36","uri":"/dataFlows/steps/39cb65bf-d464-41c0-bd16-49d48461ef36","type":"application/vnd.sas.data.flow.step.summary"},{"method":"GET","rel":"up","href":"/dataFlows/steps","uri":"/dataFlows/steps","type":"application/vnd.sas.collection","itemType":"application/vnd.sas.data.flow.step.summary"},{"method":"PUT","rel":"update","href":"/dataFlows/steps/39cb65bf-d464-41c0-bd16-49d48461ef36","uri":"/dataFlows/steps/39cb65bf-d464-41c0-bd16-49d48461ef36","type":"application/vnd.sas.data.flow.step","responseType":"application/vnd.sas.data.flow.step"},{"method":"DELETE","rel":"delete","href":"/dataFlows/steps/39cb65bf-d464-41c0-bd16-49d48461ef36","uri":"/dataFlows/steps/39cb65bf-d464-41c0-bd16-49d48461ef36"},{"method":"POST","rel":"copy","href":"/dataFlows/steps/39cb65bf-d464-41c0-bd16-49d48461ef36/copy","uri":"/dataFlows/steps/39cb65bf-d464-41c0-bd16-49d48461ef36/copy","responseType":"application/vnd.sas.data.flow.step"},{"method":"GET","rel":"transferExport","href":"/dataFlows/steps/39cb65bf-d464-41c0-bd16-49d48461ef36","uri":"/dataFlows/steps/39cb65bf-d464-41c0-bd16-49d48461ef36","responseType":"application/vnd.sas.transfer.object"},{"method":"PUT","rel":"transferImportUpdate","href":"/dataFlows/steps/39cb65bf-d464-41c0-bd16-49d48461ef36","uri":"/dataFlows/steps/39cb65bf-d464-41c0-bd16-49d48461ef36","type":"application/vnd.sas.transfer.object","responseType":"application/vnd.sas.summary"}],"metadataVersion":1,"version":2,"type":"code","flowMetadata":{"outputPorts":[{"name":"output_table","displayName":"output_table","localDisplayName":"output_table","minEntries":1,"maxEntries":1,"defaultEntries":0,"type":"table"}]},"ui":"{\"showPageContentOnly\": true, \"pages\": [{\"id\": \"params\", \"type\": \"page\", \"label\": \"Parameters\", \"children\": [{\"id\": \"section_input_params\", \"type\": \"section\", \"label\": \"Input Parameters\", \"open\": true, \"children\": [{\"id\": \"input_option\", \"type\": \"radiogroup\", \"label\": \"Select your input type:\", \"items\": [{\"value\": \"single\", \"label\": \"Single parquet file\"}, {\"value\": \"multiple\", \"label\": \"Multiple parquet files in a folder\"}], \"visible\": \"\"}, {\"id\": \"parquet_file_path\", \"type\": \"path\", \"label\": \"Enter path to parquet file (should be located on the SAS server):\", \"pathtype\": \"file\", \"placeholder\": \"\", \"required\": false, \"visible\": [\"$input_option\", \"=\", \"single\"], \"enabled\": [\"$input_option\", \"=\", \"single\"]}, {\"id\": \"parquet_path\", \"type\": \"path\", \"label\": \"Enter path to folder containing parquet files (should be located on the SAS server):\", \"pathtype\": \"folder\", \"placeholder\": \"\", \"required\": false, \"visible\": [\"$input_option\", \"=\", \"multiple\"], \"enabled\": [\"$input_option\", \"=\", \"multiple\"]}, {\"id\": \"output_table\", \"type\": \"outputtable\", \"label\": \"Output table (preferably a data set backed by a DuckDB libname)\", \"required\": true, \"placeholder\": \"\", \"visible\": \"\"}]}]}, {\"id\": \"about\", \"type\": \"page\", \"label\": \"About\", \"children\": [{\"id\": \"section_about_intro\", \"type\": \"section\", \"label\": \"DuckDB - Introspect Parquet Metadata\", \"open\": true, \"visible\": \"\", \"children\": [{\"id\": \"section_about_intro_text\", \"type\": \"text\", \"text\": \"This custom step extracts and outputs metadata from input parquet files. A future plan is that, based on user parameters, the step modifies parquet reflecting in changed metadata, particularly partitioning information and rowgroups to optimise query performance.  It takes advantage of the SAS/ACCESS Interface to DuckDB and inbuilt functions to work with parquet files.\\n\\nOpen file formats such as Parquet are popular due to the benefits they offer in reduced data footprint and columnar structure.  Also, DuckDB has gained popularity as a performant query processing engine which reduces data movement.  Functions available as part of DuckDB Parquet support provide useful tools which assist query engines to use parquet file metadata better.\", \"visible\": \"\"}, {\"id\": \"section_about_parameters\", \"type\": \"section\", \"label\": \"Parameters\", \"open\": false, \"visible\": \"\", \"children\": [{\"id\": \"section_about_parameters_input\", \"type\": \"section\", \"label\": \"Input Parameters\", \"open\": false, \"children\": [{\"id\": \"section_about_parameters_input_text\", \"type\": \"text\", \"text\": \"- Path to parquet file(file selector, required): select only files on the SAS server (i.e. the filesystem). Based on earlier selection, these correspond to a single parquet file or a folder comprising multiple files.\\n\\n\", \"visible\": \"\"}]}, {\"id\": \"section_about_parameters_output\", \"type\": \"section\", \"label\": \"Output specification\", \"open\": true, \"visible\": \"\", \"children\": [{\"id\": \"section_about_parameters_output_text\", \"type\": \"text\", \"text\": \"- Output table (output port, required): select an output table which holds schema results.  Choose based on your use case, but it's preferred that this belongs to a DuckDB libname. \", \"visible\": \"\"}]}]}, {\"id\": \"section_about_version\", \"type\": \"section\", \"label\": \"About this step\", \"open\": true, \"children\": [{\"id\": \"version_text\", \"type\": \"text\", \"text\": \"Version: 0.1.0 (04FEB2026)\\nContact: Sundaresh Sankaran (Sundaresh.sankaran@sas.com)\"}]}]}]}], \"syntaxversion\": \"1.3.0\", \"values\": {\"input_option\": {\"value\": \"single\", \"label\": \"Single parquet file\"}, \"parquet_file_path\": \"\", \"parquet_path\": \"\", \"function_name\": [], \"output_table\": {\"library\": \"\", \"table\": \"\"}}}","localUi":"{\"pages\":[{\"children\":[{\"children\":[{\"id\":\"input_option\",\"items\":[{\"label\":\"Single parquet file\",\"value\":\"single\"},{\"label\":\"Multiple parquet files in a folder\",\"value\":\"multiple\"}],\"label\":\"Select your input type:\",\"type\":\"radiogroup\",\"visible\":\"\"},{\"enabled\":[\"$input_option\",\"=\",\"single\"],\"id\":\"parquet_file_path\",\"label\":\"Enter path to parquet file (should be located on the SAS server):\",\"pathtype\":\"file\",\"placeholder\":\"\",\"required\":false,\"type\":\"path\",\"visible\":[\"$input_option\",\"=\",\"single\"]},{\"enabled\":[\"$input_option\",\"=\",\"multiple\"],\"id\":\"parquet_path\",\"label\":\"Enter path to folder containing parquet files (should be located on the SAS server):\",\"pathtype\":\"folder\",\"placeholder\":\"\",\"required\":false,\"type\":\"path\",\"visible\":[\"$input_option\",\"=\",\"multiple\"]},{\"id\":\"output_table\",\"label\":\"Output table (preferably a data set backed by a DuckDB libname)\",\"placeholder\":\"\",\"required\":true,\"type\":\"outputtable\",\"visible\":\"\"}],\"id\":\"section_input_params\",\"label\":\"Input Parameters\",\"open\":true,\"type\":\"section\"}],\"id\":\"params\",\"label\":\"Parameters\",\"type\":\"page\"},{\"children\":[{\"children\":[{\"id\":\"section_about_intro_text\",\"text\":\"This custom step extracts and outputs metadata from input parquet files. A future plan is that, based on user parameters, the step modifies parquet reflecting in changed metadata, particularly partitioning information and rowgroups to optimise query performance.  It takes advantage of the SAS/ACCESS Interface to DuckDB and inbuilt functions to work with parquet files.\\n\\nOpen file formats such as Parquet are popular due to the benefits they offer in reduced data footprint and columnar structure.  Also, DuckDB has gained popularity as a performant query processing engine which reduces data movement.  Functions available as part of DuckDB Parquet support provide useful tools which assist query engines to use parquet file metadata better.\",\"type\":\"text\",\"visible\":\"\"},{\"children\":[{\"children\":[{\"id\":\"section_about_parameters_input_text\",\"text\":\"- Path to parquet file(file selector, required): select only files on the SAS server (i.e. the filesystem). Based on earlier selection, these correspond to a single parquet file or a folder comprising multiple files.\\n\\n\",\"type\":\"text\",\"visible\":\"\"}],\"id\":\"section_about_parameters_input\",\"label\":\"Input Parameters\",\"open\":false,\"type\":\"section\"},{\"children\":[{\"id\":\"section_about_parameters_output_text\",\"text\":\"- Output table (output port, required): select an output table which holds schema results.  Choose based on your use case, but it's preferred that this belongs to a DuckDB libname. \",\"type\":\"text\",\"visible\":\"\"}],\"id\":\"section_about_parameters_output\",\"label\":\"Output specification\",\"open\":true,\"type\":\"section\",\"visible\":\"\"}],\"id\":\"section_about_parameters\",\"label\":\"Parameters\",\"open\":false,\"type\":\"section\",\"visible\":\"\"},{\"children\":[{\"id\":\"version_text\",\"text\":\"Version: 0.1.0 (04FEB2026)\\nContact: Sundaresh Sankaran (Sundaresh.sankaran@sas.com)\",\"type\":\"text\"}],\"id\":\"section_about_version\",\"label\":\"About this step\",\"open\":true,\"type\":\"section\"}],\"id\":\"section_about_intro\",\"label\":\"DuckDB - Introspect Parquet Metadata\",\"open\":true,\"type\":\"section\",\"visible\":\"\"}],\"id\":\"about\",\"label\":\"About\",\"type\":\"page\"}],\"showPageContentOnly\":true,\"syntaxversion\":\"1.3.0\",\"values\":{\"function_name\":[],\"input_option\":{\"label\":\"Single parquet file\",\"value\":\"single\"},\"output_table\":{\"library\":\"\",\"table\":\"\"},\"parquet_file_path\":\"\",\"parquet_path\":\"\"}}","templates":{"SAS":"/* SAS templated code goes here */\n\n/* -------------------------------------------------------------------------------------------*\n   DuckDB - Aggregate Parquets - Version 1.3.0\n\n   This program dynamically builds a DuckDB SQL aggregation query and\n   pushes it down to Duck DB through the SAS/ACCESS Interface to Duck DB.\n   \n   This version refactored to follow the structural patterns, macro usage and\n   verbose commenting style used by the \"LLM - Azure OpenAI In-context Learning.sas\"\n   program while preserving the original purpose and logic.\n\n   Author: Sundaresh Sankaran (original)\n   Refactor: Polished after AI-assisted automation\n   Version: 1.3.0 (2026-02-03)\n*-------------------------------------------------------------------------------------------- */\n\n/* -------------------------------------------------------------------------------------------*\n    User Parameters\n    \n    The parameters below allow customization of the aggregation operation,\n    including the input file path, aggregation functions, columns to aggregate,\n    grouping columns, and output table.\n    \n    Users can modify these parameters to suit their specific data and analysis needs.\n* -------------------------------------------------------------------------------------------- */\n\n/* Input option: 'single' for a single parquet file, 'multiple' for all parquet files in a folder */\n/* %let input_option=single; */\n\n/*  Directory or prefix containing parquet files  */\n/* %let parquet_file_path=sasserver:/mnt/viya-share/data/parquet-test/ss-new/parquet-test/HMEQ_WITH_CUST.parquet; */\n\n \n\n/* Aggregation function list: define count then each function name macro */\n/* %let function_name_count=4; */\n/* %let function_name_1=AVG; */\n/* %let function_name_2=SUM; */\n/* %let function_name_3=STDDEV; */\n/* %let function_name_4=COUNT; */\n\n/* Comma-separated list of columns to aggregate and group-by columns (space or comma separated OK)  */\n/* %let agg_columns=DELINQ DEBTINC;                    */\n/* %let group_by_columns= ;                  */\n\n/* Where clause to filter parquet data before aggregation (optional) */\n/* %let where_clause=       BAD=1; */\n\n/*  Output table assigned to the Duck DB engine. Provide libname-qualified name if desired.  */\n/* %let output_table=dukonce.TABLE_NUM_AGGS_DD; */\n\n\n\n\n/* -----------------------------------------------------------------------------------------*\n   Macros\n\n   The macros below follow the structural conventions used in prior custom steps by author:\n\n   - small utility macros for runtime triggers and error flags\n   - a focused macro to build SQL strings and one to execute the Duck DB query\n*------------------------------------------------------------------------------------------*/\n\n/* -------------------------------------------------------------------------------------------* \n   Macro to initialize a run-time trigger global macro variable to run SAS Studio Custom Steps. \n   A value of 1 (the default) enables this custom step to run.  A value of 0 (provided by \n   upstream code) sets this to disabled.\n\n   Input:\n   1. triggerName: The name of the runtime trigger you wish to create. Ensure you provide a \n      unique value to this parameter since it will be declared as a global variable.\n\n   Output:\n   2. &triggerName : A global variable which takes the name provided to triggerName.\n*-------------------------------------------------------------------------------------------- */\n\n%macro _create_runtime_trigger(triggerName);\n   %global &triggerName.;\n   %if %sysevalf(%superq(&triggerName.)=, boolean)  %then %do;\n      %put NOTE: Trigger macro variable &triggerName. does not exist. Creating it now.;\n      %let &triggerName.=1;\n   %end;\n%mend _create_runtime_trigger;\n\n\n/* -----------------------------------------------------------------------------------------* \n   Macro to create an error flag for capture during code execution.\n\n   Input:\n      1. errorFlagName: The name of the error flag you wish to create. Ensure you provide a \n         unique value to this parameter since it will be declared as a global variable.\n      2. errorFlagDesc: A description to add to the error flag.\n\n    Output:\n      1. &errorFlagName : A global variable which takes the name provided to errorFlagName.\n      2. &errorFlagDesc : A global variable which takes the name provided to errorFlagDesc.\n*------------------------------------------------------------------------------------------ */\n\n%macro _create_error_flag(errorFlagName, errorFlagDesc);\n\n   %global &errorFlagName.;\n   %let &errorFlagName.=0;\n   %global &errorFlagDesc.;\n\n%mend _create_error_flag;\n\n\n/* -----------------------------------------------------------------------------------------* \n  Macro: _create_sql_string\n  Purpose: Build the comma-separated list of aggregate expressions and the\n           group-by column list suitable for injection into the DuckDB SQL.\n  Behavior: Does not execute SQL; only constructs macro variables:\n            - &final_agg_columns.  (aggregations with aliases)\n            - &final_group_by_columns. (comma-separated grouping columns)\n  Output:\n      1. &final_agg_columns : A global variable which contains a string of aggregation functions.\n      2. &final_group_by_columns : A global variable which contains a comma-separated list of group-by columns.\n*------------------------------------------------------------------------------------------ */\n\n%macro _create_sql_string;\n\n    %global final_agg_columns final_group_by_columns group_by_clause;\n    %local i function_name;\n    %let final_agg_columns=;\n\n    %put NOTE: &function_name_count. functions have been selected.;\n\n    %do i = 1 %to &function_name_count.;\n\n        %let function_name = &&function_name_&i.;\n        %put NOTE: Constructing query for function &function_name.;\n\n        data _null_;\n            length new $32767. match new_match $100. start len 8.;\n            /* Surrounding double-quotes let the macro variable &function_name insert into the pattern */\n            new = prxchange('s/\\s+/,/i', -1, trim(\"&agg_columns.\"));\n\n            /* Firstly, we construct a wrapper around each variable to derive a basic expression to call a function */\n            new = prxchange(\"s/([A-Za-z0-9_]+(?:-[A-Za-z0-9_]+)*)/&function_name.($1) AS &function_name._$1/i\", -1, new );  \n           \n            /* Then, we handle the case of column names with hyphens (swearing softly under our breath) */\n            /* SAS PRX functions to the rescue */\n\n            pos=1;\n            if _n_ = 1 then pattern_id=PRXPARSE(\"/&function_name._([A-Za-z0-9_]+(?:-[A-Za-z0-9_]+)*)*/\");\n            length = length(new);\n  \n            /* Iterate over all matches */\n            call prxnext(pattern_id, pos, length, new, start, len);\n            \n            do while (start > 0);\n                match = substr(new, start, len);\n                put \"NOTE: Matched a hyphen pattern - \" match;\n                new_match = trim(transtrn(match,\"-\",\"_\"));\n                new_match = trim(transtrn(new_match,\"-\",\"_\"));\n                put \"NOTE: Changed pattern to - \" new_match;\n                new = transtrn(new,trim(match),trim(new_match));\n                call prxnext(pattern_id, pos, length, new, start, len);\n            end;\n\n            /* Finally, a garnish - DuckDB SQL might mistakenly consider symbols as operators, and therefore let us wrap them... */\n            new = prxchange(\"s/&function_name.\\(([A-Za-z0-9_]+(?:-[A-Za-z0-9_]+)*)\\)/&function_name.(\"||'\"'||\"$1\"||'\"'||\")/i\", -1, new ); \n            \n            call symput(\"new_agg_columns_&i.\", trim(new));\n\n        run;\n\n        %if &i = 1 %then %do;\n            %let final_agg_columns=&&new_agg_columns_&i..;\n        %end;\n        %else %do;\n            %let final_agg_columns=&final_agg_columns., &&new_agg_columns_&i..;\n        %end;\n\n    %end;\n\n    %put NOTE: The final aggregation expression is &final_agg_columns.;\n\n    %put NOTE: Starting build of group by expression.;\n    %put NOTE: Group by columns provided are &group_by_columns.;\n\n/* Create GROUP BY clause only if group-by columns are provided */\n    %if \"&group_by_columns.\" = \"\" %then %do;\n      %put NOTE: No GROUP BY columns provided. No group by expression will be built.;\n      %let final_group_by_columns=;\n      %let group_by_clause=;\n    %end;\n    %else %do;\n    \n         data _null_;\n            /* Take care of hyphens in group-by columns */\n            new = trim(prxchange(\"s/([A-Za-z0-9_]+(?:-[A-Za-z0-9_]+)*)/\"||'\"'||\"$1\"||'\"'||\"/i\", -1, \"&group_by_columns.\" ));\n            /* Convert whitespace-separated quoted group-by columns to comma-separated list */\n            new=transtrn(trim(new),\" \",\",\");\n            call symput('final_group_by_columns',new);\n         run;\n        %put NOTE: Final group by columns is &final_group_by_columns.;\n        %let group_by_clause=group by &final_group_by_columns.;\n        %let final_group_by_columns=&final_group_by_columns.,;\n        %put NOTE: The final group by expression is &final_group_by_columns. ; \n    %end;\n\n/* Create WHERE clause only if a filter is provided */\n      %if \"&where_clause.\" = \"\" %then %do;\n         %put NOTE: No WHERE clause provided. No filtering will be applied.;\n         %let where_clause=;\n      %end;\n      %else %do;\n         %put NOTE: WHERE clause provided is &where_clause.;\n         %let wherec=%sysfunc(substr(%str(&where_clause.),1,6));\n         %let wherec=%upcase(%str(&wherec.));\n         %let wherec=%trim(%str(&wherec.));\n         %if \"&wherec.\"=\"WHERE\" %then %do;\n            %let where_clause=&where_clause.;\n         %end;\n         %else %do;\n            %put NOTE: Adding WHERE keyword to the clause.;\n            %let where_clause=WHERE &where_clause.;\n         %end;\n      %end;\n    \n%mend _create_sql_string;\n\n\n/* -----------------------------------------------------------------------------------------* \n   Macro to identify whether a given folder location provided from a \n   SAS Studio Custom Step folder selector happens to be a SAS Content folder\n   or a folder on the filesystem (SAS Server).\n\n   Input:\n   1. pathReference: A path reference provided by the file or folder selector control in \n      a SAS Studio Custom step.\n\n   Output:\n   1. _path_identifier: Set inside macro, a global variable indicating the prefix of the \n      path provided.\n\n   Also available at: https://raw.githubusercontent.com/SundareshSankaran/sas_utility_programs/main/code/Identify%20SAS%20Content%20or%20Server/macro_identify_sas_content_server.sas\n\n*------------------------------------------------------------------------------------------ */\n\n%macro _identify_content_or_server(pathReference);\n   %global _path_identifier;\n   data _null_;\n      call symput(\"_path_identifier\", scan(%str(&pathReference.),1,\":\",\"MO\"));\n   run;\n   %put NOTE: _path_identifier is &_path_identifier. ;\n%mend _identify_content_or_server;\n\n/* -----------------------------------------------------------------------------------------* \n   Macro to extract the path provided from a SAS Studio Custom Step file or folder selector.\n\n   Input:\n   1. pathReference: A path reference provided by the file or folder selector control in \n      a SAS Studio Custom step.\n\n   Output:\n   1. _sas_folder_path: Set inside macro, a global variable containing the path.\n\n   Also available at: https://raw.githubusercontent.com/SundareshSankaran/sas_utility_programs/main/code/Extract%20SAS%20Folder%20Path/macro_extract_sas_folder_path.sas\n\n*------------------------------------------------------------------------------------------ */\n\n%macro _extract_sas_folder_path(pathReference);\n\n   %global _sas_folder_path;\n\n   data _null_;\n      call symput(\"_sas_folder_path\", scan(%str(&pathReference.),2,\":\",\"MO\"));\n   run;\n\n%mend _extract_sas_folder_path;\n\n/* -----------------------------------------------------------------------------------------* \n  Macro: _assign_input_file_path\n  Purpose: Based on the type of input selected, assign either the value of a path to a single\n           parquet file or a glob pointing to all parquet files in a folder.\n   Output:\n      1. &_input_file_path : A global variable which contains the resolved input file path.\n*------------------------------------------------------------------------------------------ */\n\n%macro _assign_input_file_path;\n    %global _input_file_path;\n\n    %if \"&input_option.\"=\"single\" %then %do;\n        %let _input_file_path=&parquet_file_path.;\n    %end;\n    %if \"&input_option.\"=\"multiple\" %then %do;\n        data _null_;\n            call symput(\"_input_file_path\",%str(\"&parquet_path./*.parquet\"));\n        run;\n    %end;\n\n    %put NOTE: The input file path has been set as \"&_input_file_path.\";\n\n%mend _assign_input_file_path;\n\n/* -----------------------------------------------------------------------------------------* \n  Macro: _duckdb_execute_aggregations\n  Purpose: Build the SQL (via create_sql_string) and run a direct connection\n           to the Duck DB engine, executing the aggregation and returning\n           the results from the pushed-down query.\n   Behavior: Connects to DuckDB, executes aggregation query, creates output table.\n*------------------------------------------------------------------------------------------ */\n\n%macro _duckdb_execute_aggregations;\n    \n   %put NOTE: Step 1 - Assign in-memory DuckDB libname.;\n\n   %if &_duckdb_error_flag. = 0 %then %do;\n      libname dukonce duckdb;\n   %end;\n\n   %put NOTE: Step 2 - Assign input file path macro variable.;\n\n   %if &_duckdb_error_flag.=0 %then %do;\n      %_assign_input_file_path;\n   %end;\n\n   \n   %put NOTE: Step 3 - Identify if this file reference is on Server or Content.;\n\n   %if &_duckdb_error_flag. = 0 %then %do;\n      %_identify_content_or_server(\"&_input_file_path.\");\n\n      %if \"&_path_identifier.\"=\"sasserver\" %then %do;\n         %put NOTE: Folder location prefixed with &_path_identifier. is on the SAS Server.;\n      %end;\n\n      %else %do;\n\n         %let _duckdb_error_flag=1;\n         %put ERROR: Please select a valid file on the SAS Server (filesystem). ;\n         data _null_;\n            call symputx(\"_duckdb_error_desc\", \"Please select a valid file on the SAS Server (filesystem).\");\n         run;\n      \n      %end;\n   %end;\n\n   %put NOTE: Step 4 - Extract the path from the input_file_path macro variable.;\n\n   %if &_duckdb_error_flag. = 0 %then %do;\n\n      %_extract_sas_folder_path(\"&_input_file_path.\");\n\n      %if \"&_sas_folder_path.\" = \"\" %then %do;\n\n         %let _duckdb_error_flag = 1;\n         %let _duckdb_error_desc = The field is empty, please select a valid path  ;\n         %put ERROR: &_duckdb_error_desc. ;\n\n      %end;\n      %else %do;\n         %let file_path=&_sas_folder_path.;\n         %put NOTE: Extracted file path is &file_path.;\n      %end;\n   %end;\n\n   %put NOTE: Step 5 - Build SQL Aggregation string and group by string.;\n   %if &_duckdb_error_flag. = 0 %then %do;\n        %put NOTE: Building SQL aggregation strings...;\n        %_create_sql_string;\n   %end;\n\n   %put NOTE: Aggregation string resolves to &final_agg_columns.;\n   %put NOTE: Group by columns resolve to &final_group_by_columns.;\n\n   %put NOTE: Step 6 - Execute DuckDB aggregation query and create output table.;\n\n   %if &_duckdb_error_flag. = 0 %then %do;\n        %put NOTE: Executing DuckDB aggregation query...;\n        proc sql;\n            connect using dukonce;\n            create table &output_table. (replace=yes) as\n            select * from connection to dukonce(\n                select \n                &final_group_by_columns.\n                &final_agg_columns.\n                from read_parquet(\"&file_path.\")\n                &where_clause.\n                &group_by_clause.\n                \n            );\n        quit;\n   %end;\n   %else %do;\n        %let _duckdb_error_desc = Cannot execute DuckDB aggregation query.; \n        %put ERROR: &_duckdb_error_desc.;\n   %end;\n\n%mend _duckdb_execute_aggregations;\n\n\n/* -----------------------------------------------------------------------------------------* \n  Execution Control\n*------------------------------------------------------------------------------------------ */\n%put NOTE: Starting duckdb aggregations program (v1.3.0)...;\n%_create_error_flag(_duckdb_error_flag, _duckdb_error_desc);\n\n%put NOTE: Step 0 - 0.1 - Error Flag & Desc variable created.;\n\n%_create_runtime_trigger(_duckdb_run_trigger);\n\n%put NOTE: Step 0 - 0.2 - Runtime trigger value is &_duckdb_run_trigger.;\n\n%if &_duckdb_run_trigger. = 1 %then %do;\n   %_duckdb_execute_aggregations;\n%end;\n\n%if &_duckdb_run_trigger. = 0 %then %do;\n   %put NOTE: This step has been disabled. Nothing to do.;\n%end;\n\n\n/* ----------------------------------------------------------------------------------* \n    Cleanup \n*------------------------------------------------------------------------------------------ */\n%put NOTE: Step CLEANUP - CLEANUP.1 - Clean up global macro variables created during execution;\n\n%if %symexist(final_agg_columns) %then %do;\n   %symdel final_agg_columns;\n%end;\n\n%if %symexist(_input_file_path) %then %do;\n   %symdel _input_file_path;\n%end;\n\n%if %symexist(_SAS_FOLDER_PATH) %then %do;\n   %symdel _SAS_FOLDER_PATH;\n%end;\n\n%if %symexist(_PATH_IDENTIFIER) %then %do;\n   %symdel _PATH_IDENTIFIER;\n%end;\n\n%if %symexist(final_group_by_columns) %then %do;\n   %symdel final_group_by_columns;\n%end;\n\n%if %symexist(group_by_clause) %then %do;\n   %symdel group_by_clause;\n%end;\n\n%if %symexist(_duckdb_run_trigger) %then %do;\n   %symdel _duckdb_run_trigger;\n%end;\n\n%if %symexist(_duckdb_run_trigger) %then %do;\n   %symdel _duckdb_run_trigger;\n%end;\n\n%if %symexist(_duckdb_run_trigger) %then %do;\n   %symdel _duckdb_run_trigger;\n%end;\n\n%if %symexist(_duckdb_error_flag) %then %do;\n   %symdel _duckdb_error_flag;\n%end;\n\n%if %symexist(_duckdb_error_desc) %then %do;\n   %symdel _duckdb_error_desc;\n%end;\n\n\n/* Remove helper macros from global symbol table */\n%put NOTE: Step CLEANUP - CLEANUP.2 - Delete helper macros from global symbol table.;\n\n%sysmacdelete _create_runtime_trigger;\n%sysmacdelete _create_error_flag;\n%sysmacdelete _create_sql_string;\n%sysmacdelete _identify_content_or_server;\n%sysmacdelete _assign_input_file_path;\n%sysmacdelete _duckdb_execute_aggregations;\n%sysmacdelete _extract_sas_folder_path;\n\n%put NOTE: duckdb aggregations program (v1.3.0) completed.;"}}
