{"creationTimeStamp":"2026-02-16T20:40:02.520024Z","createdBy":"Sundaresh.Sankaran@sas.com","modifiedTimeStamp":"2026-02-16T20:40:02.520024Z","modifiedBy":"Sundaresh.Sankaran@sas.com","id":"6622ed51-2854-4b13-bf92-c19f499fa911","name":"DuckDB - Introspect Parquet Metadata.step","displayName":"DuckDB - Introspect Parquet Metadata.step","localDisplayName":"DuckDB - Introspect Parquet Metadata.step","links":[{"method":"GET","rel":"self","href":"/dataFlows/steps/6622ed51-2854-4b13-bf92-c19f499fa911","uri":"/dataFlows/steps/6622ed51-2854-4b13-bf92-c19f499fa911","type":"application/vnd.sas.data.flow.step"},{"method":"GET","rel":"alternate","href":"/dataFlows/steps/6622ed51-2854-4b13-bf92-c19f499fa911","uri":"/dataFlows/steps/6622ed51-2854-4b13-bf92-c19f499fa911","type":"application/vnd.sas.data.flow.step.summary"},{"method":"GET","rel":"up","href":"/dataFlows/steps","uri":"/dataFlows/steps","type":"application/vnd.sas.collection","itemType":"application/vnd.sas.data.flow.step.summary"},{"method":"PUT","rel":"update","href":"/dataFlows/steps/6622ed51-2854-4b13-bf92-c19f499fa911","uri":"/dataFlows/steps/6622ed51-2854-4b13-bf92-c19f499fa911","type":"application/vnd.sas.data.flow.step","responseType":"application/vnd.sas.data.flow.step"},{"method":"DELETE","rel":"delete","href":"/dataFlows/steps/6622ed51-2854-4b13-bf92-c19f499fa911","uri":"/dataFlows/steps/6622ed51-2854-4b13-bf92-c19f499fa911"},{"method":"POST","rel":"copy","href":"/dataFlows/steps/6622ed51-2854-4b13-bf92-c19f499fa911/copy","uri":"/dataFlows/steps/6622ed51-2854-4b13-bf92-c19f499fa911/copy","responseType":"application/vnd.sas.data.flow.step"},{"method":"GET","rel":"transferExport","href":"/dataFlows/steps/6622ed51-2854-4b13-bf92-c19f499fa911","uri":"/dataFlows/steps/6622ed51-2854-4b13-bf92-c19f499fa911","responseType":"application/vnd.sas.transfer.object"},{"method":"PUT","rel":"transferImportUpdate","href":"/dataFlows/steps/6622ed51-2854-4b13-bf92-c19f499fa911","uri":"/dataFlows/steps/6622ed51-2854-4b13-bf92-c19f499fa911","type":"application/vnd.sas.transfer.object","responseType":"application/vnd.sas.summary"}],"metadataVersion":1,"version":2,"type":"code","flowMetadata":{"outputPorts":[{"name":"output_table","displayName":"output_table","localDisplayName":"output_table","minEntries":1,"maxEntries":1,"defaultEntries":0,"type":"table"}]},"ui":"{\"showPageContentOnly\": true, \"pages\": [{\"id\": \"params\", \"type\": \"page\", \"label\": \"Parameters\", \"children\": [{\"id\": \"section_input_params\", \"type\": \"section\", \"label\": \"Input Parameters\", \"open\": true, \"children\": [{\"id\": \"input_option\", \"type\": \"radiogroup\", \"label\": \"Select your input type:\", \"items\": [{\"value\": \"single\", \"label\": \"Single parquet file\"}, {\"value\": \"multiple\", \"label\": \"Multiple parquet files in a folder\"}], \"visible\": \"\"}, {\"id\": \"parquet_file_path\", \"type\": \"path\", \"label\": \"Enter path to parquet file (should be located on the SAS server):\", \"pathtype\": \"file\", \"placeholder\": \"\", \"required\": false, \"visible\": [\"$input_option\", \"=\", \"single\"], \"enabled\": [\"$input_option\", \"=\", \"single\"]}, {\"id\": \"parquet_path\", \"type\": \"path\", \"label\": \"Enter path to folder containing parquet files (should be located on the SAS server):\", \"pathtype\": \"folder\", \"placeholder\": \"\", \"required\": false, \"visible\": [\"$input_option\", \"=\", \"multiple\"], \"enabled\": [\"$input_option\", \"=\", \"multiple\"]}]}, {\"id\": \"section1\", \"type\": \"section\", \"label\": \"Output Specifications\", \"open\": true, \"children\": [{\"id\": \"load_cas\", \"type\": \"checkbox\", \"label\": \"Load output to SAS Cloud Analytics Services (CAS)\", \"visible\": \"\"}, {\"id\": \"load_cas_text\", \"type\": \"text\", \"text\": \"If checked, the output table is loaded to CAS for visualisation. The default target table is PARQUET_METADATA in PUBLIC Caslib (user can change this).\\n\\n\", \"visible\": \"\"}, {\"id\": \"target_caslib\", \"type\": \"textfield\", \"label\": \"Target CAS library name:\", \"placeholder\": \"PUBLIC\", \"required\": false, \"visible\": [\"$load_cas\", \"=\", true], \"enabled\": [\"$load_cas\", \"=\", true]}, {\"id\": \"target_tblname\", \"type\": \"textfield\", \"label\": \"Target CAS table name:\", \"placeholder\": \"PARQUET_METADATA\", \"required\": false, \"visible\": [\"$load_cas\", \"=\", true], \"enabled\": [\"$load_cas\", \"=\", true]}, {\"id\": \"output_table\", \"type\": \"outputtable\", \"label\": \"Output table (preferably a data set backed by a DuckDB libname)\", \"required\": true, \"placeholder\": \"\", \"visible\": \"\"}, {\"id\": \"write_parquet\", \"type\": \"checkbox\", \"label\": \"Write new parquet file (for single parquet files only) and specify metadata options \", \"visible\": [\"$input_option\", \"=\", \"single\"], \"enabled\": [\"$input_option\", \"=\", \"single\"]}]}, {\"id\": \"section_parquet_writer\", \"type\": \"section\", \"label\": \"Parquet Writer Specifications\", \"open\": true, \"visible\": [[\"$write_parquet\", \"=\", true], \"&\", [\"$input_option\", \"=\", \"single\"]], \"enabled\": [[\"$write_parquet\", \"=\", true], \"&\", [\"$input_option\", \"=\", \"single\"]], \"children\": [{\"id\": \"metadata_option_tbl\", \"type\": \"optiontable\", \"label\": \"Specify metadata options:\", \"required\": false, \"tabletype\": \"authorboth\", \"initialrowcount\": 1, \"min\": null, \"max\": null, \"showcolumnlabels\": true, \"columns\": [{\"id\": \"ROW_GROUP_SIZE\", \"type\": \"numberfield\", \"required\": false, \"placeholder\": \"\", \"value\": 122880, \"integer\": true, \"max\": null, \"min\": 2048, \"excludemax\": false, \"excludemin\": false, \"label\": \"ROW_GROUP_SIZE\"}, {\"id\": \"ROW_GROUP_SIZE_BYTES\", \"type\": \"textfield\", \"label\": \"ROW_GROUP_SIZE_BYTES\", \"placeholder\": \"\", \"required\": false, \"value\": \"'512MB'\"}, {\"id\": \"ROW_GROUPS_PER_FILE\", \"type\": \"numberfield\", \"required\": false, \"label\": \"ROW_GROUPS_PER_FILE\", \"placeholder\": \"\", \"value\": 8, \"integer\": true, \"max\": null, \"min\": 8, \"excludemax\": false, \"excludemin\": false}, {\"id\": \"COMPRESSION\", \"type\": \"dropdown\", \"label\": \"COMPRESSION\", \"placeholder\": \"\", \"required\": false, \"value\": {\"value\": \"'ZSTD'\", \"label\": \"ZSTD\"}, \"items\": [{\"value\": \"'SNAPPY'\", \"label\": \"SNAPPY\"}, {\"value\": \"'GZIP'\", \"label\": \"GZIP\"}, {\"value\": \"'LZ4'\", \"label\": \"LZ4\"}, {\"value\": \"'ZSTD'\", \"label\": \"ZSTD\"}, {\"value\": \"'UNCOMPRESSED'\", \"label\": \"UNCOMPRESSED\"}, {\"value\": \"'BROTLI'\", \"label\": \"BROTLI\"}]}, {\"id\": \"S_D_PAGE_SIZE_LIMIT\", \"type\": \"numberfield\", \"required\": false, \"label\": \"STRING_DICTIONARY_PAGE_SIZE_LIMIT\", \"placeholder\": \"\", \"value\": 100000, \"integer\": true, \"max\": null, \"min\": null, \"excludemax\": false, \"excludemin\": false}], \"repeatref\": null}, {\"id\": \"metadata_options_text\", \"type\": \"text\", \"text\": \"We will seek to support additional options in future versions.\", \"visible\": \"\"}, {\"id\": \"order_by_cols\", \"type\": \"textfield\", \"label\": \"Specify comma-separated list of columns to order by:\", \"placeholder\": \"\", \"required\": false, \"visible\": \"\"}, {\"id\": \"output_parquet_folder\", \"type\": \"path\", \"label\": \"Select output folder:\", \"pathtype\": \"folder\", \"placeholder\": \"\", \"required\": false, \"visible\": \"\"}, {\"id\": \"output_parquet_name\", \"type\": \"textfield\", \"label\": \"Specify output filename (include .parquet extension):\", \"placeholder\": \"\", \"required\": false, \"visible\": \"\", \"indent\": 0}]}]}, {\"id\": \"about\", \"type\": \"page\", \"label\": \"About\", \"children\": [{\"id\": \"section_about_intro\", \"type\": \"section\", \"label\": \"DuckDB - Introspect Parquet Metadata\", \"open\": true, \"visible\": \"\", \"children\": [{\"id\": \"section_about_intro_text\", \"type\": \"text\", \"text\": \"DuckDB - Introspect Parquet Metadata\\n================================\\nThis custom step extracts and outputs metadata from input parquet files. It also gives you an option to load this output to SAS Cloud Analytics Services (CAS) table for visualisation. Further, based on user-specified parameters, the step can write parquet files reflecting changed metadata, particularly partitioning information and rowgroups that optimise query performance.  It takes advantage of the SAS/ACCESS Interface to DuckDB and inbuilt functions to work with parquet files.\\n\\nOpen file formats such as parquet are popular due to benefits they offer in reduced data footprint and columnar structure.  Also, DuckDB is a popular and performant query processing engine that reduces data movement.  DuckDB Parquet functions are useful tools that assist query engines to use parquet file metadata better.\", \"visible\": \"\"}, {\"id\": \"section_about_parameters\", \"type\": \"section\", \"label\": \"Parameters\", \"open\": false, \"visible\": \"\", \"children\": [{\"id\": \"section_about_parameters_input\", \"type\": \"section\", \"label\": \"Input Parameters\", \"open\": false, \"children\": [{\"id\": \"section_about_parameters_input_text\", \"type\": \"text\", \"text\": \"- Path to parquet file(file selector, required): select only files on the SAS server (i.e. the filesystem). Based on earlier selection, this could be a single parquet file or a folder comprising multiple files.\\n\\n\", \"visible\": \"\"}]}, {\"id\": \"section_about_parameters_output\", \"type\": \"section\", \"label\": \"Output specification\", \"open\": true, \"visible\": \"\", \"children\": [{\"id\": \"section_about_parameters_output_text\", \"type\": \"text\", \"text\": \"1. Output table (output port, required): select an output table to hold schema results.  \\n\\n2. Load to CAS (checkbox, optional): if checked, the output table is loaded to CAS for visualisation. The default table is PARQUET_METADATA in PUBLIC caslib (can be changed by user).\", \"visible\": \"\"}]}, {\"id\": \"section_about_parameters_parquet_write\", \"type\": \"section\", \"label\": \"Parquet writer options\", \"open\": true, \"visible\": \"\", \"children\": [{\"id\": \"section_about_parameters_output_text_1\", \"type\": \"text\", \"text\": \"1. Select whether you want to write to a new parquet file with new metadata options (you will be able to overwrite existing file if you give the same name).\\n\\n2. Order By Columns (text field):  Parquet rowgroups and metadata provide best value when planned in alignment with commonly queried columns.  Specify an Order By clause (without the \\\"ORDER BY\\\") in comma-separated form listing columns that you would like the new table to be ordered by.\\n\\n3. Parquet writer options (option table): Change options for the new file if you wish. A limited set of options are offered as parquet writer options are numerous and differ based on DuckDB version.\", \"visible\": \"\"}]}]}, {\"id\": \"section_about_version\", \"type\": \"section\", \"label\": \"About this step\", \"open\": true, \"children\": [{\"id\": \"version_text\", \"type\": \"text\", \"text\": \"Version: 0.5.1 (16FEB2026)\\nContact: Sundaresh Sankaran (Sundaresh.sankaran@sas.com)\"}]}]}]}], \"syntaxversion\": \"1.3.0\", \"values\": {\"input_option\": {\"value\": \"single\", \"label\": \"Single parquet file\"}, \"parquet_file_path\": \"\", \"parquet_path\": \"\", \"load_cas\": false, \"target_caslib\": \"PUBLIC\", \"target_tblname\": \"PARQUET_METADATA\", \"output_table\": {\"library\": \"\", \"table\": \"\"}, \"write_parquet\": false, \"metadata_option_tbl\": null, \"order_by_cols\": \"\", \"output_parquet_folder\": \"\", \"output_parquet_name\": \"\"}}","localUi":"{\"pages\":[{\"children\":[{\"children\":[{\"id\":\"input_option\",\"items\":[{\"label\":\"Single parquet file\",\"value\":\"single\"},{\"label\":\"Multiple parquet files in a folder\",\"value\":\"multiple\"}],\"label\":\"Select your input type:\",\"type\":\"radiogroup\",\"visible\":\"\"},{\"enabled\":[\"$input_option\",\"=\",\"single\"],\"id\":\"parquet_file_path\",\"label\":\"Enter path to parquet file (should be located on the SAS server):\",\"pathtype\":\"file\",\"placeholder\":\"\",\"required\":false,\"type\":\"path\",\"visible\":[\"$input_option\",\"=\",\"single\"]},{\"enabled\":[\"$input_option\",\"=\",\"multiple\"],\"id\":\"parquet_path\",\"label\":\"Enter path to folder containing parquet files (should be located on the SAS server):\",\"pathtype\":\"folder\",\"placeholder\":\"\",\"required\":false,\"type\":\"path\",\"visible\":[\"$input_option\",\"=\",\"multiple\"]}],\"id\":\"section_input_params\",\"label\":\"Input Parameters\",\"open\":true,\"type\":\"section\"},{\"children\":[{\"id\":\"load_cas\",\"label\":\"Load output to SAS Cloud Analytics Services (CAS)\",\"type\":\"checkbox\",\"visible\":\"\"},{\"id\":\"load_cas_text\",\"text\":\"If checked, the output table is loaded to CAS for visualisation. The default target table is PARQUET_METADATA in PUBLIC Caslib (user can change this).\\n\\n\",\"type\":\"text\",\"visible\":\"\"},{\"enabled\":[\"$load_cas\",\"=\",true],\"id\":\"target_caslib\",\"label\":\"Target CAS library name:\",\"placeholder\":\"PUBLIC\",\"required\":false,\"type\":\"textfield\",\"visible\":[\"$load_cas\",\"=\",true]},{\"enabled\":[\"$load_cas\",\"=\",true],\"id\":\"target_tblname\",\"label\":\"Target CAS table name:\",\"placeholder\":\"PARQUET_METADATA\",\"required\":false,\"type\":\"textfield\",\"visible\":[\"$load_cas\",\"=\",true]},{\"id\":\"output_table\",\"label\":\"Output table (preferably a data set backed by a DuckDB libname)\",\"placeholder\":\"\",\"required\":true,\"type\":\"outputtable\",\"visible\":\"\"},{\"enabled\":[\"$input_option\",\"=\",\"single\"],\"id\":\"write_parquet\",\"label\":\"Write new parquet file (for single parquet files only) and specify metadata options \",\"type\":\"checkbox\",\"visible\":[\"$input_option\",\"=\",\"single\"]}],\"id\":\"section1\",\"label\":\"Output Specifications\",\"open\":true,\"type\":\"section\"},{\"children\":[{\"columns\":[{\"excludemax\":false,\"excludemin\":false,\"id\":\"ROW_GROUP_SIZE\",\"integer\":true,\"label\":\"ROW_GROUP_SIZE\",\"max\":null,\"min\":2048,\"placeholder\":\"\",\"required\":false,\"type\":\"numberfield\",\"value\":122880},{\"id\":\"ROW_GROUP_SIZE_BYTES\",\"label\":\"ROW_GROUP_SIZE_BYTES\",\"placeholder\":\"\",\"required\":false,\"type\":\"textfield\",\"value\":\"'512MB'\"},{\"excludemax\":false,\"excludemin\":false,\"id\":\"ROW_GROUPS_PER_FILE\",\"integer\":true,\"label\":\"ROW_GROUPS_PER_FILE\",\"max\":null,\"min\":8,\"placeholder\":\"\",\"required\":false,\"type\":\"numberfield\",\"value\":8},{\"id\":\"COMPRESSION\",\"items\":[{\"label\":\"SNAPPY\",\"value\":\"'SNAPPY'\"},{\"label\":\"GZIP\",\"value\":\"'GZIP'\"},{\"label\":\"LZ4\",\"value\":\"'LZ4'\"},{\"label\":\"ZSTD\",\"value\":\"'ZSTD'\"},{\"label\":\"UNCOMPRESSED\",\"value\":\"'UNCOMPRESSED'\"},{\"label\":\"BROTLI\",\"value\":\"'BROTLI'\"}],\"label\":\"COMPRESSION\",\"placeholder\":\"\",\"required\":false,\"type\":\"dropdown\",\"value\":{\"label\":\"ZSTD\",\"value\":\"'ZSTD'\"}},{\"excludemax\":false,\"excludemin\":false,\"id\":\"S_D_PAGE_SIZE_LIMIT\",\"integer\":true,\"label\":\"STRING_DICTIONARY_PAGE_SIZE_LIMIT\",\"max\":null,\"min\":null,\"placeholder\":\"\",\"required\":false,\"type\":\"numberfield\",\"value\":100000}],\"id\":\"metadata_option_tbl\",\"initialrowcount\":1,\"label\":\"Specify metadata options:\",\"max\":null,\"min\":null,\"repeatref\":null,\"required\":false,\"showcolumnlabels\":true,\"tabletype\":\"authorboth\",\"type\":\"optiontable\"},{\"id\":\"metadata_options_text\",\"text\":\"We will seek to support additional options in future versions.\",\"type\":\"text\",\"visible\":\"\"},{\"id\":\"order_by_cols\",\"label\":\"Specify comma-separated list of columns to order by:\",\"placeholder\":\"\",\"required\":false,\"type\":\"textfield\",\"visible\":\"\"},{\"id\":\"output_parquet_folder\",\"label\":\"Select output folder:\",\"pathtype\":\"folder\",\"placeholder\":\"\",\"required\":false,\"type\":\"path\",\"visible\":\"\"},{\"id\":\"output_parquet_name\",\"indent\":0,\"label\":\"Specify output filename (include .parquet extension):\",\"placeholder\":\"\",\"required\":false,\"type\":\"textfield\",\"visible\":\"\"}],\"enabled\":[[\"$write_parquet\",\"=\",true],\"\\u0026\",[\"$input_option\",\"=\",\"single\"]],\"id\":\"section_parquet_writer\",\"label\":\"Parquet Writer Specifications\",\"open\":true,\"type\":\"section\",\"visible\":[[\"$write_parquet\",\"=\",true],\"\\u0026\",[\"$input_option\",\"=\",\"single\"]]}],\"id\":\"params\",\"label\":\"Parameters\",\"type\":\"page\"},{\"children\":[{\"children\":[{\"id\":\"section_about_intro_text\",\"text\":\"DuckDB - Introspect Parquet Metadata\\n================================\\nThis custom step extracts and outputs metadata from input parquet files. It also gives you an option to load this output to SAS Cloud Analytics Services (CAS) table for visualisation. Further, based on user-specified parameters, the step can write parquet files reflecting changed metadata, particularly partitioning information and rowgroups that optimise query performance.  It takes advantage of the SAS/ACCESS Interface to DuckDB and inbuilt functions to work with parquet files.\\n\\nOpen file formats such as parquet are popular due to benefits they offer in reduced data footprint and columnar structure.  Also, DuckDB is a popular and performant query processing engine that reduces data movement.  DuckDB Parquet functions are useful tools that assist query engines to use parquet file metadata better.\",\"type\":\"text\",\"visible\":\"\"},{\"children\":[{\"children\":[{\"id\":\"section_about_parameters_input_text\",\"text\":\"- Path to parquet file(file selector, required): select only files on the SAS server (i.e. the filesystem). Based on earlier selection, this could be a single parquet file or a folder comprising multiple files.\\n\\n\",\"type\":\"text\",\"visible\":\"\"}],\"id\":\"section_about_parameters_input\",\"label\":\"Input Parameters\",\"open\":false,\"type\":\"section\"},{\"children\":[{\"id\":\"section_about_parameters_output_text\",\"text\":\"1. Output table (output port, required): select an output table to hold schema results.  \\n\\n2. Load to CAS (checkbox, optional): if checked, the output table is loaded to CAS for visualisation. The default table is PARQUET_METADATA in PUBLIC caslib (can be changed by user).\",\"type\":\"text\",\"visible\":\"\"}],\"id\":\"section_about_parameters_output\",\"label\":\"Output specification\",\"open\":true,\"type\":\"section\",\"visible\":\"\"},{\"children\":[{\"id\":\"section_about_parameters_output_text_1\",\"text\":\"1. Select whether you want to write to a new parquet file with new metadata options (you will be able to overwrite existing file if you give the same name).\\n\\n2. Order By Columns (text field):  Parquet rowgroups and metadata provide best value when planned in alignment with commonly queried columns.  Specify an Order By clause (without the \\\"ORDER BY\\\") in comma-separated form listing columns that you would like the new table to be ordered by.\\n\\n3. Parquet writer options (option table): Change options for the new file if you wish. A limited set of options are offered as parquet writer options are numerous and differ based on DuckDB version.\",\"type\":\"text\",\"visible\":\"\"}],\"id\":\"section_about_parameters_parquet_write\",\"label\":\"Parquet writer options\",\"open\":true,\"type\":\"section\",\"visible\":\"\"}],\"id\":\"section_about_parameters\",\"label\":\"Parameters\",\"open\":false,\"type\":\"section\",\"visible\":\"\"},{\"children\":[{\"id\":\"version_text\",\"text\":\"Version: 0.5.1 (16FEB2026)\\nContact: Sundaresh Sankaran (Sundaresh.sankaran@sas.com)\",\"type\":\"text\"}],\"id\":\"section_about_version\",\"label\":\"About this step\",\"open\":true,\"type\":\"section\"}],\"id\":\"section_about_intro\",\"label\":\"DuckDB - Introspect Parquet Metadata\",\"open\":true,\"type\":\"section\",\"visible\":\"\"}],\"id\":\"about\",\"label\":\"About\",\"type\":\"page\"}],\"showPageContentOnly\":true,\"syntaxversion\":\"1.3.0\",\"values\":{\"input_option\":{\"label\":\"Single parquet file\",\"value\":\"single\"},\"load_cas\":false,\"metadata_option_tbl\":null,\"order_by_cols\":\"\",\"output_parquet_folder\":\"\",\"output_parquet_name\":\"\",\"output_table\":{\"library\":\"\",\"table\":\"\"},\"parquet_file_path\":\"\",\"parquet_path\":\"\",\"target_caslib\":\"PUBLIC\",\"target_tblname\":\"PARQUET_METADATA\",\"write_parquet\":false}}","templates":{"SAS":"/* SAS templated code goes here */\n\n/* -------------------------------------------------------------------------------------------*\n   DuckDB - Introspect Parquet Metadata - Version 0.5.1\n\n   This custom step extracts and outputs metadata from input parquet files. \n   A future plan is that, based on user parameters, the step modifies parquet reflecting in \n   changed metadata, particularly partitioning information and rowgroups to optimise query \n   performance.  \n   \n   It takes advantage of the SAS/ACCESS Interface to DuckDB and inbuilt functions to work \n   with parquet files.\n\n   Author: Sundaresh Sankaran (original)\n   Refactor: Polished after AI-assisted automation\n   Version: 0.5.1 (16FEB2026)\n*-------------------------------------------------------------------------------------------- */\n\n/* -------------------------------------------------------------------------------------------*\n    User Parameters\n    \n    The parameters below allow customization of the aggregation operation,\n    including the input file path, aggregation functions, columns to aggregate,\n    grouping columns, and output table.\n    \n    Users can modify these parameters to suit their specific data and analysis needs.\n* -------------------------------------------------------------------------------------------- */\n\n/* Input option: 'single' for a single parquet file, 'multiple' for all parquet files in a folder */\n/* %let input_option=single; */\n\n/*  Directory or prefix containing parquet files  */\n/* %let parquet_file_path=sasserver:/mnt/viya-share/data/parquet-test/ss-new/parquet-test/HMEQ_WITH_CUST.parquet; */\n\n \n/* %let parquet_path=sasserver:/mnt/viya-share/data/parquet-test/ss-new/parquet-test; */\n\n\n/*  Output table assigned to the Duck DB engine. Provide libname-qualified name if desired.  */\n/* %let output_table=dukonce.TABLE_NUM_AGGS_DD; */\n\n\n\n\n/* -----------------------------------------------------------------------------------------*\n   Macros\n\n   The macros below follow the structural conventions used in prior custom steps by author:\n\n   - small utility macros for runtime triggers and error flags\n   - a focused macro to build SQL strings and one to execute the Duck DB query\n*------------------------------------------------------------------------------------------*/\n\n/* -------------------------------------------------------------------------------------------* \n   Macro to initialize a run-time trigger global macro variable to run SAS Studio Custom Steps. \n   A value of 1 (the default) enables this custom step to run.  A value of 0 (provided by \n   upstream code) sets this to disabled.\n\n   Input:\n   1. triggerName: The name of the runtime trigger you wish to create. Ensure you provide a \n      unique value to this parameter since it will be declared as a global variable.\n\n   Output:\n   2. &triggerName : A global variable which takes the name provided to triggerName.\n*-------------------------------------------------------------------------------------------- */\n\n%macro _create_runtime_trigger(triggerName);\n   %global &triggerName.;\n   %if %sysevalf(%superq(&triggerName.)=, boolean)  %then %do;\n      %put NOTE: Trigger macro variable &triggerName. does not exist. Creating it now.;\n      %let &triggerName.=1;\n   %end;\n%mend _create_runtime_trigger;\n\n\n/* -----------------------------------------------------------------------------------------* \n   Macro to create an error flag for capture during code execution.\n\n   Input:\n      1. errorFlagName: The name of the error flag you wish to create. Ensure you provide a \n         unique value to this parameter since it will be declared as a global variable.\n      2. errorFlagDesc: A description to add to the error flag.\n\n    Output:\n      1. &errorFlagName : A global variable which takes the name provided to errorFlagName.\n      2. &errorFlagDesc : A global variable which takes the name provided to errorFlagDesc.\n*------------------------------------------------------------------------------------------ */\n\n%macro _create_error_flag(errorFlagName, errorFlagDesc);\n\n   %global &errorFlagName.;\n   %let &errorFlagName.=0;\n   %global &errorFlagDesc.;\n\n%mend _create_error_flag;\n\n\n/* -----------------------------------------------------------------------------------------* \n   Macro to identify whether a given folder location provided from a \n   SAS Studio Custom Step folder selector happens to be a SAS Content folder\n   or a folder on the filesystem (SAS Server).\n\n   Input:\n   1. pathReference: A path reference provided by the file or folder selector control in \n      a SAS Studio Custom step.\n\n   Output:\n   1. _path_identifier: Set inside macro, a global variable indicating the prefix of the \n      path provided.\n\n   Also available at: https://raw.githubusercontent.com/SundareshSankaran/sas_utility_programs/main/code/Identify%20SAS%20Content%20or%20Server/macro_identify_sas_content_server.sas\n\n*------------------------------------------------------------------------------------------ */\n\n%macro _identify_content_or_server(pathReference);\n   %global _path_identifier;\n   data _null_;\n      call symput(\"_path_identifier\", scan(%str(&pathReference.),1,\":\",\"MO\"));\n   run;\n   %put NOTE: _path_identifier is &_path_identifier. ;\n%mend _identify_content_or_server;\n\n/* -----------------------------------------------------------------------------------------* \n   Macro to extract the path provided from a SAS Studio Custom Step file or folder selector.\n\n   Input:\n   1. pathReference: A path reference provided by the file or folder selector control in \n      a SAS Studio Custom step.\n\n   Output:\n   1. _sas_folder_path: Set inside macro, a global variable containing the path.\n\n   Also available at: https://raw.githubusercontent.com/SundareshSankaran/sas_utility_programs/main/code/Extract%20SAS%20Folder%20Path/macro_extract_sas_folder_path.sas\n\n*------------------------------------------------------------------------------------------ */\n\n%macro _extract_sas_folder_path(pathReference);\n\n   %global _sas_folder_path;\n\n   data _null_;\n      call symput(\"_sas_folder_path\", scan(%str(&pathReference.),2,\":\",\"MO\"));\n   run;\n\n%mend _extract_sas_folder_path;\n\n/* -----------------------------------------------------------------------------------------* \n  Macro: _assign_input_file_path\n  Purpose: Based on the type of input selected, assign either the value of a path to a single\n           parquet file or a glob pointing to all parquet files in a folder.\n   Output:\n      1. &_input_file_path : A global variable which contains the resolved input file path.\n*------------------------------------------------------------------------------------------ */\n\n%macro _assign_input_file_path;\n    %global _input_file_path;\n\n    %if \"&input_option.\"=\"single\" %then %do;\n        %let _input_file_path=&parquet_file_path.;\n    %end;\n    %if \"&input_option.\"=\"multiple\" %then %do;\n        data _null_;\n            call symput(\"_input_file_path\",%str(\"&parquet_path./*.parquet\"));\n        run;\n    %end;\n\n    %put NOTE: The input file path has been set as \"&_input_file_path.\";\n\n%mend _assign_input_file_path;\n\n\n\n/* -----------------------------------------------------------------------------------------* \n  EXECUTION Macro: _dpm_execution_macro\n  Purpose: Extract metadata and write to output table.\n   Behavior: Connects to DuckDB, extracts metadata, creates output table.\n*------------------------------------------------------------------------------------------ */\n\n%macro _dpm_execution_macro;\n    \n   %put NOTE: Step 1 - Assign in-memory DuckDB libname.;\n\n   %if &_duckdb_error_flag. = 0 %then %do;\n      libname dukonce duckdb;\n   %end;\n\n   %put NOTE: Step 2 - Assign input file path macro variable.;\n\n   %if &_duckdb_error_flag.=0 %then %do;\n      %_assign_input_file_path;\n   %end;\n\n   \n   %put NOTE: Step 3 - Identify if this file reference is on Server or Content.;\n\n   %if &_duckdb_error_flag. = 0 %then %do;\n      %_identify_content_or_server(\"&_input_file_path.\");\n\n      %if \"&_path_identifier.\"=\"sasserver\" %then %do;\n         %put NOTE: Folder location prefixed with &_path_identifier. is on the SAS Server.;\n      %end;\n\n      %else %do;\n\n         %let _duckdb_error_flag=1;\n         %put ERROR: Please select a valid file on the SAS Server (filesystem). ;\n         data _null_;\n            call symputx(\"_duckdb_error_desc\", \"&_duckdb_error_desc. <-> Please select a valid file on the SAS Server (filesystem).\");\n         run;\n      \n      %end;\n\n   %end;\n\n   %put NOTE: Step 4 - Extract the path from the input_file_path macro variable.;\n\n   %if &_duckdb_error_flag. = 0 %then %do;\n\n      %_extract_sas_folder_path(\"&_input_file_path.\");\n\n      %if \"&_sas_folder_path.\" = \"\" %then %do;\n\n         %let _duckdb_error_flag = 1;\n         %let _duckdb_error_desc = &_duckdb_error_desc. <-> The field is empty, please select a valid path  ;\n         %put ERROR: &_duckdb_error_desc. ;\n\n      %end;\n      %else %do;\n         %let file_path=&_sas_folder_path.;\n         %put NOTE: Extracted file path is &file_path.;\n      %end;\n   %end;\n\n\n    %if &_duckdb_error_flag. = 0 %then %do;\n         %if \"&input_option.\"=\"single\" %then %do;\n            %let file_path=&file_path.;\n        %end;\n        %if \"&input_option.\"=\"multiple\" %then %do;\n            data _null_;\n                call symput(\"file_path\",%str(\"&file_path./*.parquet\"));\n            run;\n        %end;\n   %end;\n\n\n   %put NOTE: Step 5 - Execute DuckDB metadata extraction and create output table.;\n\n   %if &_duckdb_error_flag. = 0 %then %do;\n        %put NOTE: Executing DuckDB metadata extraction query...;\n        proc sql;\n            connect using dukonce;\n            create table &output_table. (replace=yes) as\n            select * from connection to dukonce(\n                select \n                * from parquet_metadata(\"&file_path.\")\n                \n            );\n        run;\n        quit;\n   %end;\n   %else %do;\n        %let _duckdb_error_desc = &_duckdb_error_desc. <-> Cannot execute DuckDB aggregation query; \n        %put ERROR: &_duckdb_error_desc.;\n        %put NOTE: &_duckdb_error_flag.;\n   %end;\n\n   %if &_duckdb_error_flag. = 0 %then %do;\n        %if &load_cas. = 1 %then %do;\n            %put NOTE: Loading output table into CAS...;\n            cas mySession sessopts=(caslib=public timeout=1800);\n\n            /* === Use PROC CASUTIL to load and promote in one step === */\n            proc casutil;\n               droptable casdata=\"&target_tblname.\" incaslib=\"&target_caslib.\" quiet;\n               droptable casdata=\"&target_tblname.\" incaslib=\"&target_caslib.\" quiet;\n               load data=&output_table. casout=\"&target_tblname.\" outcaslib=\"&target_caslib.\" promote;\n               run;\n            quit;\n\n            cas mySession terminate;\n            %put NOTE: DuckDB metadata extraction and output table creation completed successfully.;\n         %end;\n   %end;\n   %if \"&input_option.\"=\"single\" %then %do;\n        %if &write_parquet.=1 %then %do;\n            %if &_duckdb_error_flag.=0 %then %do;\n                %put NOTE: Writing Parquet file ;\n                %if \"&order_by_cols.\"=\"\" %then %do;\n                    %let order_by_string=;\n                %end;\n                %else %do;\n                    %let order_by_string=ORDER BY &order_by_cols.;\n                %end;\n                      \n                %_identify_content_or_server(\"&output_parquet_folder.\");\n\n                %if \"&_path_identifier.\"=\"sasserver\" %then %do;\n                    %put NOTE: Folder location prefixed with &_path_identifier. is on the SAS Server.;\n                %end;\n\n                %else %do;\n\n                    %let _duckdb_error_flag=1;\n                    %put ERROR: Please select a valid file on the SAS Server (filesystem). ;\n                    data _null_;\n                        call symputx(\"_duckdb_error_desc\", \"&_duckdb_error_desc. <-> Please select a valid output file on the SAS Server (filesystem).\");\n                    run;\n                %end;\n\n            %end;\n            %if &_duckdb_error_flag. = 0 %then %do;\n                %if \"&output_parquet_name.\"=\"\" %then %do;\n                    %let _duckdb_error_flag = 1;\n                    %let _duckdb_error_desc = &_duckdb_error_desc. <-> No parquet file name provided;\n                    %put ERROR: &_duckdb_error_desc.;\n                %end;\n            %end;\n            %if &_duckdb_error_flag.=0 %then %do;\n                %_extract_sas_folder_path(\"&output_parquet_folder.\");\n                %if \"&_sas_folder_path.\" = \"\" %then %do;\n\n                    %let _duckdb_error_flag = 1;\n                    %let _duckdb_error_desc = &_duckdb_error_desc. <-> The field is empty, please select a valid path  ;\n                    %put ERROR: &_duckdb_error_desc. ;\n\n                %end;\n                %else %do;\n                    %let output_file_path=&_sas_folder_path./&output_parquet_name.;\n                    %put NOTE: Extracted file path for output file is &output_file_path.;\n                %end;\n            %end;\n            %if &_duckdb_error_flag.=0 %then %do;\n                proc sql;\n                    connect using dukonce;\n                    execute(\n                        SET preserve_insertion_order=false;\n                        COPY (SELECT * FROM \"&file_path.\" &order_by_string.)\n                            TO \"&output_file_path.\" (\n                                FORMAT PARQUET,\n                                OVERWRITE,\n                                &METADATA_OPTION_TBL_COL_1. &METADATA_OPTION_TBL_R1_C1.,\n                                &METADATA_OPTION_TBL_COL_2. &METADATA_OPTION_TBL_R1_C2.,\n                                &METADATA_OPTION_TBL_COL_3. &METADATA_OPTION_TBL_R1_C3.,\n                                &METADATA_OPTION_TBL_COL_4. &METADATA_OPTION_TBL_R1_C4.,\n                                STRING_DICTIONARY_PAGE_SIZE_LIMIT &METADATA_OPTION_TBL_R1_C5. \n                        \n                                );\n                    ) by dukonce;\n            \n                quit;\n                %put NOTE: Output parquet file created succesfully;\n            %end;\n        %end;\n   %end;\n   %if &_duckdb_error_flag. = 1 %then %do;\n        %let _duckdb_error_desc = &_duckdb_error_desc. <-> Cannot execute DuckDB aggregation query.; \n        %put ERROR: &_duckdb_error_desc.;\n   %end;   \n\n%mend _dpm_execution_macro;\n\n/* -----------------------------------------------------------------------------------------* \n  END MACROS\n*------------------------------------------------------------------------------------------ */\n\n/* -----------------------------------------------------------------------------------------* \n  Execution Code\n*------------------------------------------------------------------------------------------ */\n%put NOTE: Starting duckdb metadata introspection program (v0.5.1)...;\n%_create_error_flag(_duckdb_error_flag, _duckdb_error_desc);\n\n%put NOTE: Step 0 - 0.1 - Error Flag & Desc variable created.;\n\n%_create_runtime_trigger(_duckdb_run_trigger);\n\n%put NOTE: Step 0 - 0.2 - Runtime trigger value is &_duckdb_run_trigger.;\n\n%if &_duckdb_run_trigger. = 1 %then %do;\n   %_dpm_execution_macro;\n%end;\n\n%if &_duckdb_run_trigger. = 0 %then %do;\n   %put NOTE: This step has been disabled. Nothing to do.;\n%end;\n\n%if &_duckdb_error_flag. = 1 %then %do;\n   %put ERROR: DuckDB metadata introspection program ended with errors. Description: &_duckdb_error_desc.;\n%end;\n\n/* ----------------------------------------------------------------------------------* \n    Cleanup \n*------------------------------------------------------------------------------------------ */\n%put NOTE: Step CLEANUP - CLEANUP.1 - Clean up global macro variables created during execution;\n\n\n\n%if %symexist(_input_file_path) %then %do;\n   %symdel _input_file_path;\n%end;\n\n%if %symexist(_SAS_FOLDER_PATH) %then %do;\n   %symdel _SAS_FOLDER_PATH;\n%end;\n\n%if %symexist(_PATH_IDENTIFIER) %then %do;\n   %symdel _PATH_IDENTIFIER;\n%end;\n\n\n%if %symexist(_duckdb_run_trigger) %then %do;\n   %symdel _duckdb_run_trigger;\n%end;\n\n%if %symexist(_duckdb_run_trigger) %then %do;\n   %symdel _duckdb_run_trigger;\n%end;\n\n%if %symexist(_duckdb_run_trigger) %then %do;\n   %symdel _duckdb_run_trigger;\n%end;\n\n%if %symexist(_duckdb_error_flag) %then %do;\n   %symdel _duckdb_error_flag;\n%end;\n\n%if %symexist(_duckdb_error_desc) %then %do;\n   %symdel _duckdb_error_desc;\n%end;\n\n\n/* Remove helper macros from global symbol table */\n%put NOTE: Step CLEANUP - CLEANUP.2 - Delete helper macros from global symbol table.;\n\n%sysmacdelete _create_runtime_trigger;\n%sysmacdelete _create_error_flag;\n\n%sysmacdelete _identify_content_or_server;\n%sysmacdelete _assign_input_file_path;\n%sysmacdelete _dpm_execution_macro;\n%sysmacdelete _extract_sas_folder_path;\n\n%put NOTE: duckdb metadata introspection program (v0.5.1) completed.;"}}
