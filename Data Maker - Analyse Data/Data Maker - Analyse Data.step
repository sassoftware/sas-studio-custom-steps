{"creationTimeStamp":"2026-01-24T01:29:27.388499Z","createdBy":"Sundaresh.Sankaran@sas.com","modifiedTimeStamp":"2026-01-24T01:29:27.388499Z","modifiedBy":"Sundaresh.Sankaran@sas.com","name":"Data Maker - Analyse Data.step","displayName":"Data Maker - Analyse Data.step","localDisplayName":"Data Maker - Analyse Data.step","links":[{"method":"GET","rel":"self","href":"/dataFlows/steps/8252fc22-19ff-4d9a-9591-3a596a9ff910","uri":"/dataFlows/steps/8252fc22-19ff-4d9a-9591-3a596a9ff910","type":"application/vnd.sas.data.flow.step"},{"method":"GET","rel":"alternate","href":"/dataFlows/steps/8252fc22-19ff-4d9a-9591-3a596a9ff910","uri":"/dataFlows/steps/8252fc22-19ff-4d9a-9591-3a596a9ff910","type":"application/vnd.sas.data.flow.step.summary"},{"method":"GET","rel":"up","href":"/dataFlows/steps","uri":"/dataFlows/steps","type":"application/vnd.sas.collection","itemType":"application/vnd.sas.data.flow.step.summary"},{"method":"PUT","rel":"update","href":"/dataFlows/steps/8252fc22-19ff-4d9a-9591-3a596a9ff910","uri":"/dataFlows/steps/8252fc22-19ff-4d9a-9591-3a596a9ff910","type":"application/vnd.sas.data.flow.step","responseType":"application/vnd.sas.data.flow.step"},{"method":"DELETE","rel":"delete","href":"/dataFlows/steps/8252fc22-19ff-4d9a-9591-3a596a9ff910","uri":"/dataFlows/steps/8252fc22-19ff-4d9a-9591-3a596a9ff910"},{"method":"POST","rel":"copy","href":"/dataFlows/steps/8252fc22-19ff-4d9a-9591-3a596a9ff910/copy","uri":"/dataFlows/steps/8252fc22-19ff-4d9a-9591-3a596a9ff910/copy","responseType":"application/vnd.sas.data.flow.step"},{"method":"GET","rel":"transferExport","href":"/dataFlows/steps/8252fc22-19ff-4d9a-9591-3a596a9ff910","uri":"/dataFlows/steps/8252fc22-19ff-4d9a-9591-3a596a9ff910","responseType":"application/vnd.sas.transfer.object"},{"method":"PUT","rel":"transferImportUpdate","href":"/dataFlows/steps/8252fc22-19ff-4d9a-9591-3a596a9ff910","uri":"/dataFlows/steps/8252fc22-19ff-4d9a-9591-3a596a9ff910","type":"application/vnd.sas.transfer.object","responseType":"application/vnd.sas.summary"}],"metadataVersion":1,"version":2,"type":"code","flowMetadata":{"outputPorts":[{"name":"output_table","displayName":"output_table","localDisplayName":"output_table","minEntries":1,"maxEntries":1,"defaultEntries":0,"type":"table"}]},"ui":"{\"showPageContentOnly\": true, \"pages\": [{\"id\": \"params\", \"type\": \"page\", \"label\": \"Parameters\", \"children\": [{\"id\": \"section_input_params\", \"type\": \"section\", \"label\": \"Input Parameters\", \"open\": true, \"children\": [{\"id\": \"input_option\", \"type\": \"radiogroup\", \"label\": \"Select your input type:\", \"items\": [{\"value\": \"single\", \"label\": \"Single parquet file\"}, {\"value\": \"multiple\", \"label\": \"Multiple parquet files in a folder\"}], \"visible\": \"\"}, {\"id\": \"parquet_file_path\", \"type\": \"path\", \"label\": \"Enter path to parquet file (should be located on the SAS server):\", \"pathtype\": \"file\", \"placeholder\": \"\", \"required\": false, \"visible\": [\"$input_option\", \"=\", \"single\"], \"enabled\": [\"$input_option\", \"=\", \"single\"]}, {\"id\": \"parquet_path\", \"type\": \"path\", \"label\": \"Enter path to folder containing parquet files (should be located on the SAS server):\", \"pathtype\": \"folder\", \"placeholder\": \"\", \"required\": false, \"visible\": [\"$input_option\", \"=\", \"multiple\"], \"enabled\": [\"$input_option\", \"=\", \"multiple\"]}, {\"id\": \"output_table\", \"type\": \"outputtable\", \"label\": \"Output table\", \"required\": true, \"placeholder\": \"\", \"visible\": \"\"}]}]}, {\"id\": \"about\", \"type\": \"page\", \"label\": \"About\", \"children\": [{\"id\": \"section_about_intro\", \"type\": \"section\", \"label\": \"Data Maker - Analyse Data\", \"open\": true, \"visible\": \"\", \"children\": [{\"id\": \"section_about_intro_text\", \"type\": \"text\", \"text\": \"This custom step analyses parquet files - a common format for analysis and particularly used as input for Data Maker - and writes summary statistics to an output table. We expect these results to drive data configuration decisions when training synthetic data generators in SAS Data Maker.\", \"visible\": \"\"}, {\"id\": \"section_about_parameters\", \"type\": \"section\", \"label\": \"Parameters\", \"open\": false, \"visible\": \"\", \"children\": [{\"id\": \"section_about_parameters_input\", \"type\": \"section\", \"label\": \"Input Parameters\", \"open\": true, \"children\": [{\"id\": \"section_about_parameters_input_text\", \"type\": \"text\", \"text\": \"- Path to parquet file(file or folder selector, required): select only files on the SAS server (i.e. the filesystem). Based on data engineers' choice, this could be either a single parquet or a folder containing multiple parquet files. \\n\", \"visible\": \"\"}]}, {\"id\": \"section_about_parameters_output\", \"type\": \"section\", \"label\": \"Output specification\", \"open\": true, \"visible\": \"\", \"children\": [{\"id\": \"section_about_parameters_output_text\", \"type\": \"text\", \"text\": \"- Output table (output port, required): select an output table. The output table should belong to a currently active and accessible library. \", \"visible\": \"\"}]}]}, {\"id\": \"section_about_version\", \"type\": \"section\", \"label\": \"About this step\", \"open\": true, \"children\": [{\"id\": \"version_text\", \"type\": \"text\", \"text\": \"Version: 0.2.0 (23JAN2026)\\nContact: Sundaresh Sankaran (Sundaresh.sankaran@sas.com)\"}]}]}]}], \"syntaxversion\": \"1.3.0\", \"values\": {\"input_option\": {\"value\": \"single\", \"label\": \"Single parquet file\"}, \"parquet_file_path\": \"\", \"parquet_path\": \"\", \"output_table\": {\"library\": \"\", \"table\": \"\"}}}","localUi":"{\"pages\":[{\"children\":[{\"children\":[{\"id\":\"input_option\",\"items\":[{\"label\":\"Single parquet file\",\"value\":\"single\"},{\"label\":\"Multiple parquet files in a folder\",\"value\":\"multiple\"}],\"label\":\"Select your input type:\",\"type\":\"radiogroup\",\"visible\":\"\"},{\"enabled\":[\"$input_option\",\"=\",\"single\"],\"id\":\"parquet_file_path\",\"label\":\"Enter path to parquet file (should be located on the SAS server):\",\"pathtype\":\"file\",\"placeholder\":\"\",\"required\":false,\"type\":\"path\",\"visible\":[\"$input_option\",\"=\",\"single\"]},{\"enabled\":[\"$input_option\",\"=\",\"multiple\"],\"id\":\"parquet_path\",\"label\":\"Enter path to folder containing parquet files (should be located on the SAS server):\",\"pathtype\":\"folder\",\"placeholder\":\"\",\"required\":false,\"type\":\"path\",\"visible\":[\"$input_option\",\"=\",\"multiple\"]},{\"id\":\"output_table\",\"label\":\"Output table\",\"placeholder\":\"\",\"required\":true,\"type\":\"outputtable\",\"visible\":\"\"}],\"id\":\"section_input_params\",\"label\":\"Input Parameters\",\"open\":true,\"type\":\"section\"}],\"id\":\"params\",\"label\":\"Parameters\",\"type\":\"page\"},{\"children\":[{\"children\":[{\"id\":\"section_about_intro_text\",\"text\":\"This custom step analyses parquet files - a common format for analysis and particularly used as input for Data Maker - and writes summary statistics to an output table. We expect these results to drive data configuration decisions when training synthetic data generators in SAS Data Maker.\",\"type\":\"text\",\"visible\":\"\"},{\"children\":[{\"children\":[{\"id\":\"section_about_parameters_input_text\",\"text\":\"- Path to parquet file(file or folder selector, required): select only files on the SAS server (i.e. the filesystem). Based on data engineers' choice, this could be either a single parquet or a folder containing multiple parquet files. \\n\",\"type\":\"text\",\"visible\":\"\"}],\"id\":\"section_about_parameters_input\",\"label\":\"Input Parameters\",\"open\":true,\"type\":\"section\"},{\"children\":[{\"id\":\"section_about_parameters_output_text\",\"text\":\"- Output table (output port, required): select an output table. The output table should belong to a currently active and accessible library. \",\"type\":\"text\",\"visible\":\"\"}],\"id\":\"section_about_parameters_output\",\"label\":\"Output specification\",\"open\":true,\"type\":\"section\",\"visible\":\"\"}],\"id\":\"section_about_parameters\",\"label\":\"Parameters\",\"open\":false,\"type\":\"section\",\"visible\":\"\"},{\"children\":[{\"id\":\"version_text\",\"text\":\"Version: 0.2.0 (23JAN2026)\\nContact: Sundaresh Sankaran (Sundaresh.sankaran@sas.com)\",\"type\":\"text\"}],\"id\":\"section_about_version\",\"label\":\"About this step\",\"open\":true,\"type\":\"section\"}],\"id\":\"section_about_intro\",\"label\":\"Data Maker - Analyse Data\",\"open\":true,\"type\":\"section\",\"visible\":\"\"}],\"id\":\"about\",\"label\":\"About\",\"type\":\"page\"}],\"showPageContentOnly\":true,\"syntaxversion\":\"1.3.0\",\"values\":{\"input_option\":{\"label\":\"Single parquet file\",\"value\":\"single\"},\"output_table\":{\"library\":\"\",\"table\":\"\"},\"parquet_file_path\":\"\",\"parquet_path\":\"\"}}","templates":{"SAS":"/* SAS templated code goes here */\n\n/* -------------------------------------------------------------------------------------------*\n   Data Maker - Analyse Data\n\n   This SAS program analyses Parquet input files using DuckDB, a typical (but by NO means limiting)\n   use case being analysis prior to ingestion into SAS Data Maker for synthetic data generation.\n   The analysis job informs data configuration decisions made during synthetic data generation.\n\n   Author: [Sundaresh Sankaran](sundaresh.sankaran@sas.com)\n   Version: 0.2.0 (2026-01-23)\n*-------------------------------------------------------------------------------------------- */\n\n/* -------------------------------------------------------------------------------------------*\n    User Parameters\n    \n    The parameters below allow customization, debugging and testing of the program.\n    \n    Users can modify these parameters to run standalone and debug the program.\n    Uncomment and modify the parameters as needed.\n    \n    When running as part of a SAS Studio Custom Step, these parameters will be\n    provided by upstream code and should remain commented out.\n* -------------------------------------------------------------------------------------------- */;\n\n/* Input option: single or multiple */\n/* %let input_option=multiple;  */\n\n/*  Directory or prefix containing parquet files  */;\n/* data _null_;  */\n/*   call symput(\"parquet_path\",\"sasserver:/mnt/viya-share/data/parquet-test/ss-new/parquet-test\" );; */\n/* run;  */\n\n/* %let parquet_file_path=sasserver:/mnt/viya-share/data/parquet-test/ss-new/parquet-test/HMEQ_WITH_CUST.parquet;  */\n\n/* Output table assigned to the DuckDB engine. Provide libname-qualified name if desired. */\n/* %let output_table = WORK.TEMP_RESULTS;  */\n\n/* -----------------------------------------------------------------------------------------*\n   Macros\n\n   The macros below follow the structural conventions used in prior custom steps by author:\n\n   - small utility macros for runtime triggers and error flags\n   \n*------------------------------------------------------------------------------------------*/\n\n/* -------------------------------------------------------------------------------------------* \n   Macro to initialize a run-time trigger global macro variable to run SAS Studio Custom Steps. \n   A value of 1 (the default) enables this custom step to run.  A value of 0 (provided by \n   upstream code) sets this to disabled.\n\n   Input:\n   1. triggerName: The name of the runtime trigger you wish to create. Ensure you provide a \n      unique value to this parameter since it will be declared as a global variable.\n\n   Output:\n   2. &triggerName : A global variable which takes the name provided to triggerName.\n*-------------------------------------------------------------------------------------------- */\n\n%macro _create_runtime_trigger(triggerName);\n   %global &triggerName.;\n   %if %sysevalf(%superq(&triggerName.)=, boolean)  %then %do;\n      %put NOTE: Trigger macro variable &triggerName. does not exist. Creating it now.;\n      %let &triggerName.=1;\n   %end;\n%mend _create_runtime_trigger;\n\n\n/* -----------------------------------------------------------------------------------------* \n   Macro to create an error flag for capture during code execution.\n\n   Input:\n      1. errorFlagName: The name of the error flag you wish to create. Ensure you provide a \n         unique value to this parameter since it will be declared as a global variable.\n      2. errorFlagDesc: A description to add to the error flag.\n\n    Output:\n      1. &errorFlagName : A global variable which takes the name provided to errorFlagName.\n      2. &errorFlagDesc : A global variable which takes the name provided to errorFlagDesc.\n*------------------------------------------------------------------------------------------ */\n\n%macro _create_error_flag(errorFlagName, errorFlagDesc);\n\n   %global &errorFlagName.;\n   %let &errorFlagName.=0;\n   %global &errorFlagDesc.;\n\n%mend _create_error_flag;\n\n/* -----------------------------------------------------------------------------------------* \n   Macro to identify whether a given folder location provided from a \n   SAS Studio Custom Step folder selector happens to be a SAS Content folder\n   or a folder on the filesystem (SAS Server).\n\n   Input:\n   1. pathReference: A path reference provided by the file or folder selector control in \n      a SAS Studio Custom step.\n\n   Output:\n   1. _path_identifier: Set inside macro, a global variable indicating the prefix of the \n      path provided.\n\n   Also available at: https://raw.githubusercontent.com/SundareshSankaran/sas_utility_programs/main/code/Identify%20SAS%20Content%20or%20Server/macro_identify_sas_content_server.sas\n\n*------------------------------------------------------------------------------------------ */\n\n%macro _identify_content_or_server(pathReference);\n   %global _path_identifier;\n   data _null_;\n      call symput(\"_path_identifier\", scan(%str(&pathReference.),1,\":\",\"MO\"));\n   run;\n   %put NOTE: _path_identifier is &_path_identifier. ;\n%mend _identify_content_or_server;\n\n/* -----------------------------------------------------------------------------------------* \n   Macro to extract the path provided from a SAS Studio Custom Step file or folder selector.\n\n   Input:\n   1. pathReference: A path reference provided by the file or folder selector control in \n      a SAS Studio Custom step.\n\n   Output:\n   1. _sas_folder_path: Set inside macro, a global variable containing the path.\n\n   Also available at: https://raw.githubusercontent.com/SundareshSankaran/sas_utility_programs/main/code/Extract%20SAS%20Folder%20Path/macro_extract_sas_folder_path.sas\n\n*------------------------------------------------------------------------------------------ */\n\n%macro _extract_sas_folder_path(pathReference);\n\n   %global _sas_folder_path;\n\n   data _null_;\n      call symput(\"_sas_folder_path\", scan(%str(&pathReference.),2,\":\",\"MO\"));\n   run;\n\n%mend _extract_sas_folder_path;\n\n/* -----------------------------------------------------------------------------------------* \n  Macro: _assign_input_file_path\n  Purpose: Based on the type of input selected, assign either the value of a path to a single\n           parquet file or a glob pointing to all parquet files in a folder.\n   Output:\n      1. &_input_file_path : A global variable which contains the resolved input file path.\n*------------------------------------------------------------------------------------------ */\n\n%macro _assign_input_file_path;\n    %global _input_file_path;\n\n    %if \"&input_option.\"=\"single\" %then %do;\n        %let _input_file_path=&parquet_file_path.;\n    %end;\n    %if \"&input_option.\"=\"multiple\" %then %do;\n        data _null_;\n            call symput(\"_input_file_path\",%str(\"&parquet_path./*.parquet\"));\n        run;\n    %end;\n\n    %put NOTE: The input file path has been set as \"&_input_file_path.\";\n\n%mend _assign_input_file_path;\n\n\n/* -----------------------------------------------------------------------------------------* \n Execution Macro:\n Main macro called by execution control to analyse parquet files using DuckDB.\n*------------------------------------------------------------------------------------------ */\n\n%macro _dm_analysis_parquet(output_table=);\n\n   /* -----------------------------------------------------------------------------------------* \n   Create a libname backed by the DuckDB engine\n   *------------------------------------------------------------------------------------------ */\n   \n   %put NOTE: Step 1 - Assign in-memory DuckDB libname.;\n\n   %if &_dm_analysis_error_flag. = 0 %then %do;\n      libname DUKINHEL duckdb;;\n   %end;\n\n   %put NOTE: Step 2 - Assign input file path macro variable.;\n\n    %if &_dm_analysis_error_flag.=0 %then %do;\n      %_assign_input_file_path;\n   %end;\n   \n\n   %put NOTE: Step 3 - Identify if this file reference is on Server or Content.;\n\n   %if &_dm_analysis_error_flag. = 0 %then %do;\n      %_identify_content_or_server(\"&_input_file_path.\");\n\n      %if \"&_path_identifier.\"=\"sasserver\" %then %do;\n         %put NOTE: Folder location prefixed with &_path_identifier. is on the SAS Server.;\n      %end;\n\n      %else %do;\n\n         %let _dm_analysis_error_flag=1;\n         %put ERROR: Please select a valid file on the SAS Server (filesystem). ;\n         data _null_;\n            call symputx(\"_dm_analysis_error_desc\", \"Please select a valid file on the SAS Server (filesystem).\");\n         run;\n      \n      %end;\n   %end;  \n\n   %put NOTE: Step 4 - Extract the path from the input_file_path macro variable.;\n\n   %if &_dm_analysis_error_flag. = 0 %then %do;\n\n      %_extract_sas_folder_path(\"&_input_file_path.\");\n\n      %if \"&_sas_folder_path.\" = \"\" %then %do;\n\n         %let _dm_analysis_error_flag = 1;\n         %let _dm_analysis_error_desc = The field is empty, please select a valid path  ;\n         %put ERROR: &_dm_analysis_error_desc. ;\n\n      %end;\n      %else %do;\n         %let file_path=&_sas_folder_path.;\n         %put NOTE: Extracted file path is &file_path.;\n      %end;\n   %end;   \n\n   %if &_dm_analysis_error_flag. = 0 %then %do;\n         %if \"&input_option.\"=\"single\" %then %do;\n            %let file_path=&file_path.;\n        %end;\n        %if \"&input_option.\"=\"multiple\" %then %do;\n            data _null_;\n                call symput(\"file_path\",%str(\"&file_path./*.parquet\"));\n            run;\n        %end;\n   %end;\n\n   /* -----------------------------------------------------------------------------------------* \n   Extract columns from parquet metadata and schema\n   *------------------------------------------------------------------------------------------ */\n   %if &_dm_analysis_error_flag. = 0 %then %do;\n      %put NOTE: Step 5 - Extract parquet metadata and schema from files in &file_path..;\n      proc sql;\n         connect using DUKINHEL;\n         create table DUKINHEL.metadata_schema_table (replace=yes) as \n            select * from\n               connection to DUKINHEL(\n                  SELECT\n                     a.*,b.* \n                  FROM\n                     (\n                        SELECT \n                           *\n                        FROM \n                           parquet_metadata(\"&file_path.\") \n                     ) a \n\n                     JOIN\n\n                     (\n                        SELECT \n                           *\n                        FROM \n                           parquet_schema(\"&file_path.\") \n                     ) b\n                  ON \n                     a.file_name=b.file_name \n                     AND \n                     a.path_in_schema = b.name \n                     AND\n                     a.type = b.type\n               );\n      quit;\n   %end;\n\n   /* -----------------------------------------------------------------------------------------* \n   Build SQL aggregation strings\n   *------------------------------------------------------------------------------------------ */\n   %if &_dm_analysis_error_flag. = 0 %then %do;\n      %put NOTE: Step 6 - Build SQL aggregation strings for each column in parquet files.;\n\n      data DUKINHEL.metadata_table_sql (keep = sql_full_string replace=yes);\n         set DUKINHEL.metadata_schema_table;\n         length sql_full_string VARCHAR(*);\n         sql_leader_string = \"SELECT '\"||trim(file_name)||\"' as file_path, parse_filename('\"||trim(file_name)||\"') as filename, '\"||trim(path_in_schema)||\"' as column_name\";\n         sql_query_num =  \" COUNT(*) as total_count\";\n         sql_query_cardinality = \"COUNT(DISTINCT \"||'\"'||trim(path_in_schema)||'\"'||\") as cardinality\";\n         sql_query_missing = \"COUNT(CASE WHEN \"||'\"'||trim(path_in_schema)||'\"'||\" IS NULL THEN 1 END) as null_values\";\n         sql_query_max = \"MAX(\"||'\"'||trim(path_in_schema)||'\"'||\") as max_value\";\n         sql_query_min = \"MIN(\"||'\"'||trim(path_in_schema)||'\"'||\") as min_value\";\n         sql_query_median = \"MEDIAN(\"||'\"'||trim(path_in_schema)||'\"'||\") as median_value\";\n         if converted_type = \"DATE\" then do;\n            sql_query_avg = \"AVG(date_diff('day', DATE '1970-01-01', CAST(\"||'\"'||trim(path_in_schema)||'\"'||\" AS DATE))) as avg_value\";\n         end;\n         else if converted_type = \"TIMESTAMP\" then do;\n            sql_query_avg = \"AVG(date_diff('millisecond', TIMESTAMP '1970-01-01 00:00:00',\"||'\"'||trim(path_in_schema)||'\"'||\")::DOUBLE) as avg_value\";\n         end;\n         else if converted_type = \"TIMESTAMP_MICROS\" then do;\n            sql_query_avg = \"AVG(date_diff('microsecond', TIMESTAMP '1970-01-01 00:00:00',\"||'\"'||trim(path_in_schema)||'\"'||\")::DOUBLE) as avg_value\";\n         end;\n         else if type ne \"BYTE_ARRAY\" then do;\n            sql_query_avg = \"AVG(\"||'\"'||trim(path_in_schema)||'\"'||\") as avg_value\";\n         end; \n         else do;\n            sql_query_avg = \"SUM(NULL) as avg_value\";\n         end;\n         sql_trailer_string = \" from '\"||trim(file_name)||\"'\";\n         ARRAY sql_strings(8) sql_leader_string sql_query_num sql_query_cardinality sql_query_missing sql_query_min sql_query_median sql_query_avg sql_query_max ;\n         do i = 1 to 8;\n            if i = 1 then sql_full_string = trim(sql_strings(i));\n            else sql_full_string = trim(sql_full_string)||\", \"||trim(sql_strings(i));\n         end;\n         sql_full_string = trim(sql_full_string)||\" \"||trim(sql_trailer_string);\n      run;\n   %end;\n\n   /* -----------------------------------------------------------------------------------------* \n   Generate final SQL string to execute\n   *------------------------------------------------------------------------------------------ */\n   %if &_dm_analysis_error_flag. = 0 %then %do;\n      %put NOTE: Step 7 - Generate final SQL string to execute. ;\n\n      proc sql;\n         connect using DUKINHEL;\n         execute(\n            CREATE OR REPLACE TABLE METADATA_TABLE_SQL AS\n               SELECT DISTINCT sql_full_string FROM METADATA_TABLE_SQL;\n         ) by DUKINHEL;\n      quit;\n\n      data _null_;\n        set DUKINHEL.metadata_table_sql end = EOF;\n        call symput(\"sql_string_\"||compress(put(_n_,8.)),sql_full_string);\n        if EOF then call symputx(\"nbr_queries\",_n_);\n      run;\n\n   %end;\n\n   /* -----------------------------------------------------------------------------------------*\n   Symbolgen option turned on to transparently show the final SQL string being executed\n   *------------------------------------------------------------------------------------------ */\n   %if &_dm_analysis_error_flag. = 0 %then %do;\n      %put NOTE: Step 8 - Execute final SQL string to generate output table. ;\n      options symbolgen;\n\n   /* -----------------------------------------------------------------------------------------*\n   Execute final SQL string to generate output table\n   *------------------------------------------------------------------------------------------ */\n\n      proc sql;\n         connect using DUKINHEL;\n         execute(\n            CREATE TABLE IF NOT EXISTS RESULT_ANALYSIS (\n                file_path\tVARCHAR\t,\t \t \t \n                filename\tVARCHAR\t,\t \t \t \n                column_name\tVARCHAR\t,\t \t \t \n                total_count\tBIGINT\t,\t \t \t \n                cardinality\tBIGINT\t,\t \t \t \n                null_values\tBIGINT\t,\t \t \t \n                min_value\tVARCHAR\t,\t \t \t \n                median_value\tVARCHAR\t,\t \t \t \n                avg_value\tDOUBLE\t,\t \t \t \n                max_value\tVARCHAR\t\t\n            );\n\n            %do i = 1 %to &nbr_queries.;\n            INSERT INTO RESULT_ANALYSIS \n                &&sql_string_&i. ;\n            %end;\n\n         ) by DUKINHEL;\n\n      quit;\n\n    %end;\n\n    /* -----------------------------------------------------------------------------------------*\n    Print final output table to results window\n    *------------------------------------------------------------------------------------------ */\n\n   %if &_dm_analysis_error_flag. = 0 %then %do;\n \n     %put NOTE: Step 9 - Create output table ;\n     \n     data &output_table.;\n        set DUKINHEL.RESULT_ANALYSIS;\n      run;\n      \n      options nosymbolgen;\n\n   %end;\n   /* -----------------------------------------------------------------------------------------*\n   Print final output table to results window\n   *------------------------------------------------------------------------------------------ */\n   %if &_dm_analysis_error_flag. = 0 %then %do;\n\n      %put NOTE: Step 10 - Print final output table to results window. ;\n\n      proc print data=&output_table.;\n      run;\n\n      libname DUKINHEL clear;\n\n   %end;\n    \n%mend _dm_analysis_parquet;\n\n\n\n/* -----------------------------------------------------------------------------------------* \n  Execution Code\n*------------------------------------------------------------------------------------------ */\n%put NOTE: Starting Data Maker Analysis program (v0.2.0)...;\n%_create_error_flag(_dm_analysis_error_flag, _dm_analysis_error_desc);\n\n%put NOTE: Step 0 - 0.1 - Error Flag & Desc variable created.;\n\n%_create_runtime_trigger(_dm_analysis_run_trigger);\n\n%put NOTE: Step 0 - 0.2 - Runtime trigger value is &_dm_analysis_run_trigger.;\n\n%if &_dm_analysis_run_trigger. = 1 %then %do;\n   %put NOTE: Step EXECUTION - Running Data Maker Analysis program...;\n\n    %_dm_analysis_parquet(output_table=&output_table.);\n   \n%end;\n\n%if &_dm_analysis_run_trigger. = 0 %then %do;\n   %put NOTE: This step has been disabled. Nothing to do.;\n%end;\n\n%put NOTE:Error &_dm_analysis_error_flag.:&_dm_analysis_error_desc.;\n/* ----------------------------------------------------------------------------------* \n    Cleanup \n*------------------------------------------------------------------------------------------ */\n%put NOTE: Step CLEANUP - CLEANUP.1 - Clean up global macro variables created during execution;\n\n\n\n%if %symexist(_input_file_path) %then %do;\n   %symdel _input_file_path;\n%end;\n\n%if %symexist(_SAS_FOLDER_PATH) %then %do;\n   %symdel _SAS_FOLDER_PATH;\n%end;\n\n%if %symexist(_PATH_IDENTIFIER) %then %do;\n   %symdel _PATH_IDENTIFIER;\n%end;\n\n\n\n%if %symexist(group_by_clause) %then %do;\n   %symdel group_by_clause;\n%end;\n\n%if %symexist(_dm_analysis_run_trigger) %then %do;\n   %symdel _dm_analysis_run_trigger;\n%end;\n\n%if %symexist(_dm_analysis_error_flag) %then %do;\n   %symdel _dm_analysis_error_flag;\n%end;\n\n%if %symexist(_dm_analysis_error_desc) %then %do;\n   %symdel _dm_analysis_error_desc;\n%end;\n\n\n/* Remove helper macros from global symbol table */\n%put NOTE: Step CLEANUP - CLEANUP.2 - Delete helper macros from global symbol table.;\n\n%sysmacdelete _create_runtime_trigger;\n%sysmacdelete _create_error_flag;\n%sysmacdelete _identify_content_or_server;\n%sysmacdelete _assign_input_file_path;\n%sysmacdelete _dm_analysis_parquet;\n%sysmacdelete _extract_sas_folder_path;\n\n%put NOTE: Data Maker analysis program (v0.2.0) completed.;\n"},"eTag":"W/\"1769218167388499000\""}