{"creationTimeStamp":"2024-01-26T16:42:39.053Z","modifiedTimeStamp":"2024-01-26T16:56:48.714Z","createdBy":"sasadm","modifiedBy":"sasadm","name":"Airflow - Finalize DAG.step","displayName":"Airflow - Finalize DAG.step","localDisplayName":"Airflow - Finalize DAG.step","properties":{},"links":[{"method":"GET","rel":"self","href":"/dataFlows/steps/a5e4cf28-bd67-461c-abbd-ddbb85d9fba7","uri":"/dataFlows/steps/a5e4cf28-bd67-461c-abbd-ddbb85d9fba7","type":"application/vnd.sas.data.flow.step"},{"method":"GET","rel":"alternate","href":"/dataFlows/steps/a5e4cf28-bd67-461c-abbd-ddbb85d9fba7","uri":"/dataFlows/steps/a5e4cf28-bd67-461c-abbd-ddbb85d9fba7","type":"application/vnd.sas.data.flow.step.summary"},{"method":"GET","rel":"up","href":"/dataFlows/steps","uri":"/dataFlows/steps","type":"application/vnd.sas.collection","itemType":"application/vnd.sas.data.flow.step.summary"},{"method":"PUT","rel":"update","href":"/dataFlows/steps/a5e4cf28-bd67-461c-abbd-ddbb85d9fba7","uri":"/dataFlows/steps/a5e4cf28-bd67-461c-abbd-ddbb85d9fba7","type":"application/vnd.sas.data.flow.step","responseType":"application/vnd.sas.data.flow.step"},{"method":"DELETE","rel":"delete","href":"/dataFlows/steps/a5e4cf28-bd67-461c-abbd-ddbb85d9fba7","uri":"/dataFlows/steps/a5e4cf28-bd67-461c-abbd-ddbb85d9fba7"},{"method":"GET","rel":"transferExport","href":"/dataFlows/steps/a5e4cf28-bd67-461c-abbd-ddbb85d9fba7","uri":"/dataFlows/steps/a5e4cf28-bd67-461c-abbd-ddbb85d9fba7","responseType":"application/vnd.sas.transfer.object"},{"method":"PUT","rel":"transferImportUpdate","href":"/dataFlows/steps/a5e4cf28-bd67-461c-abbd-ddbb85d9fba7","uri":"/dataFlows/steps/a5e4cf28-bd67-461c-abbd-ddbb85d9fba7","type":"application/vnd.sas.transfer.object","responseType":"application/vnd.sas.summary"}],"metadataVersion":0.0,"version":2,"type":"code","flowMetadata":{"inputPorts":[{"name":"input_step_1","displayName":"input_step_1","localDisplayName":"input_step_1","minEntries":1,"maxEntries":1,"defaultEntries":0,"type":"table"},{"name":"input_step_2","displayName":"input_step_2","localDisplayName":"input_step_2","minEntries":0,"maxEntries":1,"defaultEntries":0,"type":"table"},{"name":"input_step_3","displayName":"input_step_3","localDisplayName":"input_step_3","minEntries":0,"maxEntries":1,"defaultEntries":0,"type":"table"},{"name":"input_step_4","displayName":"input_step_4","localDisplayName":"input_step_4","minEntries":0,"maxEntries":1,"defaultEntries":0,"type":"table"},{"name":"input_step_5","displayName":"input_step_5","localDisplayName":"input_step_5","minEntries":0,"maxEntries":1,"defaultEntries":0,"type":"table"},{"name":"input_step_6","displayName":"input_step_6","localDisplayName":"input_step_6","minEntries":0,"maxEntries":1,"defaultEntries":0,"type":"table"},{"name":"input_step_7","displayName":"input_step_7","localDisplayName":"input_step_7","minEntries":0,"maxEntries":1,"defaultEntries":0,"type":"table"},{"name":"input_step_8","displayName":"input_step_8","localDisplayName":"input_step_8","minEntries":0,"maxEntries":1,"defaultEntries":0,"type":"table"},{"name":"input_step_9","displayName":"input_step_9","localDisplayName":"input_step_9","minEntries":0,"maxEntries":1,"defaultEntries":0,"type":"table"},{"name":"input_step_10","displayName":"input_step_10","localDisplayName":"input_step_10","minEntries":0,"maxEntries":1,"defaultEntries":0,"type":"table"}],"outputPorts":[]},"ui":"{\n\t\"showPageContentOnly\": true,\n\t\"pages\": [\n\t\t{\n\t\t\t\"id\": \"page2\",\n\t\t\t\"type\": \"page\",\n\t\t\t\"label\": \"About\",\n\t\t\t\"children\": [\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"text2\",\n\t\t\t\t\t\"type\": \"text\",\n\t\t\t\t\t\"text\": \"The \\\"Airflow - Generate DAG\\\" tool is a set of 3 Custom Steps that enables SAS Studio Flow users to create an Airflow DAG (Directed Acyclic Graph) directly from a SAS Studio Flow.\\n\\n“A DAG is defined in a Python script, which represents the DAGs structure (tasks and their dependencies) as code.”\\n\\nThe 3 custom steps that need to be used together:\\n     Airflow - Initialize DAG\\n          Define the Airflow DAG properties – one per flow\\n     Airflow - Add Task\\n          Define an Airflow task to add to the DAG – one or more per flow\\n     Airflow - Finalize DAG\\n          Create the Airflow DAG Python script – one per flow\\n\\nBuilt and tested on SAS Viya Stable Release 2023.12.\\n\\nAuthor: Nicolas.Robert@sas.com\\n\\nVersion: 1.5 (26JAN2024)\",\n\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t}\n\t\t\t]\n\t\t},\n\t\t{\n\t\t\t\"id\": \"page1\",\n\t\t\t\"type\": \"page\",\n\t\t\t\"label\": \"Input/Output Tables\",\n\t\t\t\"children\": [\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"text1\",\n\t\t\t\t\t\"type\": \"text\",\n\t\t\t\t\t\"text\": \"Input/Output tables from the canvas are displayed in LTS 2023.03 in the Step bottom pane. Hidden from the end user here.\",\n\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"input_step_1\",\n\t\t\t\t\t\"type\": \"inputtable\",\n\t\t\t\t\t\"label\": \"Input task\",\n\t\t\t\t\t\"required\": true,\n\t\t\t\t\t\"placeholder\": \"\",\n\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"input_step_2\",\n\t\t\t\t\t\"type\": \"inputtable\",\n\t\t\t\t\t\"label\": \"Input task\",\n\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\"placeholder\": \"\",\n\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"input_step_3\",\n\t\t\t\t\t\"type\": \"inputtable\",\n\t\t\t\t\t\"label\": \"Input task\",\n\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\"placeholder\": \"\",\n\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"input_step_4\",\n\t\t\t\t\t\"type\": \"inputtable\",\n\t\t\t\t\t\"label\": \"Input task\",\n\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\"placeholder\": \"\",\n\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"input_step_5\",\n\t\t\t\t\t\"type\": \"inputtable\",\n\t\t\t\t\t\"label\": \"Input task\",\n\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\"placeholder\": \"\",\n\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"input_step_6\",\n\t\t\t\t\t\"type\": \"inputtable\",\n\t\t\t\t\t\"label\": \"Input task\",\n\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\"placeholder\": \"\",\n\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"input_step_7\",\n\t\t\t\t\t\"type\": \"inputtable\",\n\t\t\t\t\t\"label\": \"Input task\",\n\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\"placeholder\": \"\",\n\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"input_step_8\",\n\t\t\t\t\t\"type\": \"inputtable\",\n\t\t\t\t\t\"label\": \"Input task\",\n\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\"placeholder\": \"\",\n\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"input_step_9\",\n\t\t\t\t\t\"type\": \"inputtable\",\n\t\t\t\t\t\"label\": \"Input task\",\n\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\"placeholder\": \"\",\n\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"input_step_10\",\n\t\t\t\t\t\"type\": \"inputtable\",\n\t\t\t\t\t\"label\": \"Input task\",\n\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\"placeholder\": \"\",\n\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t}\n\t\t\t]\n\t\t}\n\t],\n\t\"syntaxversion\": \"1.3.0\",\n\t\"values\": {\n\t\t\"input_step_1\": {\n\t\t\t\"library\": \"\",\n\t\t\t\"table\": \"\"\n\t\t},\n\t\t\"input_step_2\": {\n\t\t\t\"library\": \"\",\n\t\t\t\"table\": \"\"\n\t\t},\n\t\t\"input_step_3\": {\n\t\t\t\"library\": \"\",\n\t\t\t\"table\": \"\"\n\t\t},\n\t\t\"input_step_4\": {\n\t\t\t\"library\": \"\",\n\t\t\t\"table\": \"\"\n\t\t},\n\t\t\"input_step_5\": {\n\t\t\t\"library\": \"\",\n\t\t\t\"table\": \"\"\n\t\t}\n\t}\n}","templates":{"SAS":"/* Generate DAG */\n\n%macro DAGend() ;\n\n   /* According to the number of inputs permitted - can be changed */\n   %let __maxInputs=10 ;\n   %let __input_tables= ;\n   %do i=1 %to &__maxInputs ;\n      %global input_step_&i ;\n      %let __input_tables=&__input_tables &&input_step_&i ;\n   %end ;\n   \n   %put &=__input_tables ;\n\n   /* Derive new sequence number */\n   data _null_ ;\n      retain seq 0 ;\n      set __dag__ end=eof ;\n      if __task_seq>seq then seq=__task_seq ;\n      if eof then call symput(\"__new_seq\",strip(put(seq+1,12.))) ;\n   run ;\n   %put &=__new_seq ;\n   \n   data __task__ ;\n      length __task_seq 8 __task_id __task_predecessor_id $ 36 ;\n      set &__input_tables end=eof ;\n      __task_seq=&__new_seq ;\n      __task_predecessor_id=__task_id ;\n      __task_id=\"__END__\" ;\n   run ;\n   %put _user_ ;\n   \n   data __dag__ ;\n      /* add last tasks to existing dag definition */\n      set __dag__ __task__ ;\n      /* Standardize dag_name and task_name\n      /* remove characters other than ., -, _, digits, and English letters */\n      __dag_name=compress(__dag_name,'.-',\"nk\") ;\n      __task_name=compress(__task_name,'.-',\"nk\") ;\n   run ;\n\n   /* Manage target file location */\n   /* Put global parameters back as macro-variables */\n   data _null_ ;\n      set __dag__(obs=1) ;\n      if upcase(scan(__dag_folder,1,\":\"))=\"SASSERVER\" then do ;\n         call execute(cats(\"filename dag_file '\",scan(__dag_folder,2,\":\"),\"/\",__dag_name,\".py\",\"' ;\")) ;\n      end ;\n      else do ;\n         call execute(cats(\"filename dag_file filesrvc folderPath='\",scan(__dag_folder,2,\":\"),\"' filename='\",__dag_name,\".py' ;\")) ;\n      end ;\n      array global_options{*} __global: ;\n      do i=1 to dim(global_options) ;\n         call symput(vname(global_options{i}),global_options{i}) ;\n      end ;\n   run ;\n   \n   /* Manage overwrite */\n   %global stop_now ;\n   %let stop_now=0 ;\n   data _null_ ;\n      set __dag__(obs=1) ;\n      dag_filename=cats(scan(__dag_folder,2,\":\"),\"/\",__dag_name,\".py\") ;\n      exist=fexist(\"dag_file\") ;\n      if exist=1 then putlog \"NOTE: DAG file \" dag_filename \"already exists.\" ;\n      else putlog \"NOTE: DAG file \" dag_filename \"does not exist.\" ;\n      dag_replace=input(__dag_replace,1.) ;\n      if dag_replace=1 then putlog \"NOTE: Replace DAG file is set.\" ;\n      else putlog \"NOTE: Replace DAG file is not set.\" ;\n      if exist=1 and dag_replace=0 then call symput(\"stop_now\",\"1\") ;\n   run ;\n   %if &stop_now=1 %then %do ;\n      %put ERROR: DAG file already exists and replace option is not set. ;\n      %return ;\n   %end ;\n      \n   data _null_ ;\n      file dag_file ;\n      put \"from datetime import datetime, timedelta\" ;\n      put \"from airflow import DAG, Dataset\" ;\n      put \"from airflow.sensors.filesystem import FileSensor\" ;\n      put \"from sas_airflow_provider.operators.sas_studio import SASStudioOperator\" ;\n      put \"from sas_airflow_provider.operators.sas_jobexecution import SASJobExecutionOperator\" ;\n      put \"from sas_airflow_provider.operators.sas_create_session import SASComputeCreateSession\" ;\n      put \"from sas_airflow_provider.operators.sas_delete_session import SASComputeDeleteSession\" ;\n   run ;\n\n   data _null_ ;\n      file dag_file mod ;\n      set __dag__(obs=1) ;\n\n      put ;\n      put \"dag = DAG(dag_id=\"\"\" __dag_name +(-1) \"\"\",\" ;\n\n      if __dag_description ne \"\" then do ;\n         put \"   description=\"\"\" __dag_description +(-1) \"\"\",\" ;\n      end ;\n\n      if __dag_schedule_type = \"EXPRESSION\" then do ;\n         if substr(strip(__dag_schedule_expression),1,10)=\"timedelta(\" then do ;\n            put \"   schedule=\" __dag_schedule_expression +(-1) \",\" ;\n         end ;\n         else if __dag_schedule_expression ne \"\" then do ;\n            put \"   schedule=\"\"\" __dag_schedule_expression +(-1) \"\"\",\" ;\n         end ;\n         else put \"   schedule=None,\" ;\n      end ;\n      else if __dag_schedule_type = \"DATASET\" then do ;\n         if __dag_schedule_datasets ne \"\" then do ;\n            put +3 \"schedule=[\" @ ;\n            length ds $ 256 ;\n            c2=countw(__dag_schedule_datasets,\",\",\"q\") ;\n            do j=1 to c2 ;\n               ds=strip(scan(__dag_schedule_datasets,j,\",\",\"q\")) ;\n               if j<c2 then put \"Dataset(\"\"\" ds +(-1) \"\"\"),\" @ ;\n               else put \"Dataset(\"\"\" ds +(-1) \"\"\")\" @ ;\n            end ;\n            put \"],\" ;\n         end ;\n      end ;\n   \n      if __dag_start_date ne \"\" then do ;\n         sd=input(__dag_start_date,yymmdd10.) ;\n         __dag_start_date_custom=cats(\"datetime(\",strip(put(sd,year.)),\",\",strip(put(sd,month.)),\",\",strip(put(sd,day.)),\")\") ;\n   \n         put \"   start_date=\" __dag_start_date_custom +(-1) \",\" ;\n   \n      end ;\n   \n      if __dag_end_date ne \"\" then do ;\n         ed=input(__dag_end_date,yymmdd10.) ;\n   \n         __dag_end_date_custom=cats(\"datetime(\",strip(put(ed,year.)),\",\",strip(put(ed,month.)),\",\",strip(put(ed,day.)),\")\") ;\n   \n         put \"   end_date=\" __dag_end_date_custom +(-1) \",\" ;\n   \n      end ;\n\n      if __dag_unpause ne \"0\" then do ;\n         put \"   is_paused_upon_creation=False,\" ;\n      end ;\n\n\n      if __dag_tags ne \"\" then do ;\n         put \"   tags=[\" __dag_tags +(-1) \"],\" ;\n      end ;\n   \n      put \"   catchup=\" __dag_catchup +(-1) \")\" ;\n      \n      put ;\n\n      if __global_dag_parameters ne \"\" then do ;\n         length param $ 256 ;\n         put \"global_params = {\" ;\n         c=countw(__global_dag_parameters,\",\",\"q\") ;\n         do i=1 to c ;\n            param=strip(scan(__global_dag_parameters,i,\",\",\"q\")) ;\n            if i<c then put +3 param +(-1) \",\" ;\n            else put +3 param ;\n         end ;\n         put \"}\" ;\n         put ;\n      end ;\n\n      if __dag_optimization_method = \"SERIAL\" then do ;\n         length session_name $ 36 ;\n         session_name=uuidgen() ;\n         put \"__task0 = SASComputeCreateSession(task_id=\"\"0_create_session\"\",\" ;\n         put \"   compute_context_name=\"\"\" __global_compute_context +(-1) \"\"\",\" ;\n         put \"   connection_name=\"\"\" __global_connection_name +(-1) \"\"\",\" ;\n         put \"   session_name=\"\"\" session_name +(-1) \"\"\",\" ;\n         put \"   dag=dag)\" ;\n         put ;\n         put \"__task9999 = SASComputeDeleteSession(task_id=\"\"9999_delete_session\"\",\" ;\n         put \"   connection_name=\"\"\" __global_connection_name +(-1) \"\"\",\" ;\n         put \"   compute_session_id=\"\"{{ ti.xcom_pull(key='compute_session_id', task_ids=['0_create_session'])|first }}\"\",\" ;\n         put \"   dag=dag)\" ;\n         put ;\n      end ;\n\n      /* Put __dag_optimization_method as global macro-variable for later use */\n      call symput(\"__dag_optimization_method\",strip(__dag_optimization_method)) ;\n   \n   run ;\n   \n   proc freq data=__dag__(firstobs=2 where=(__task_id ne \"__END__\")) noprint order=data ;\n      tables __task_id*__task_name*__task_type*__task_object_path*__task_code*\n             __task_fs_file*__task_fs_con_name*__task_fs_poke*__task_fs_timeout*__task_fs_mode*__task_trigger_rule*\n             __compute_context*__connection_name*__exec_log*__codegen_init_code*__codegen_wrap_code*__job_airflow_macrovars*\n             __dag_parameters*__dag_parameter_method*__task_datasets_produced\n         / out=__distinct_tasks__(drop=count percent) ;\n   run ;\n   \n   data _null_ ;\n      length task_label       $  256 \n             object_path_type $    7\n             object_path      $ 1000 \n             object_name      $  256\n             object_type      $    7\n             param_dict_name  $   32\n             code_name        $   32\n             fs_file          $  256 ;\n      file dag_file mod ;\n      set __distinct_tasks__ ;\n\n      if upcase(__task_type)=\"CODE\" then object_path_type=\"raw\" ;\n      else if upcase(scan(__task_object_path,1,\":\"))=\"SASSERVER\" then object_path_type=\"compute\" ;\n      else object_path_type=\"content\" ;\n   \n      object_path=scan(__task_object_path,2,\":\") ;\n   \n      object_name=scan(__task_object_path,-1,\":/\") ;\n\n      /* Assuming an object ending with .flw is a FLOW, and .sas (or embedded code) is a PROGram, otherwise it's a JOB */\n      if upcase(scan(object_name,-1,'.'))=\"FLW\" then object_type=\"flow\" ;\n      else if upcase(scan(object_name,-1,'.'))=\"SAS\" or upcase(__task_type)=\"CODE\" then object_type=\"program\" ;\n      else object_type=\"job\" ;\n\n      /* If task_name not empty, take it, otherwise take object name */\n      /* remove characters other than ., -, _, digits, and English letters */\n      task_label=ifc(strip(__task_name) ne \"\",strip(__task_name),catx(\"_\",put(_n_,12.),compress(object_name,'.-',\"nk\"))) ;\n\n      /* Manage embedded code */\n      if object_path_type=\"raw\" then do ;\n         task_label=ifc(strip(__task_name) ne \"\",strip(__task_name),catx(\"_\",put(_n_,12.),\"code\")) ;\n         code_name=cats(__task_id,\"_code\") ;\n         put code_name \"= '''\" ;\n         length line $ 256 ;\n         c1=countw(__task_code,\";\",\"q\") ;\n         do i=1 to c1 ;\n            line=scan(__task_code,i,\";\",\"q\") ;\n            put line \";\" ;\n         end ;\n         put \"'''\" ;\n         put ;\n      end ; \n   \n      if __compute_context = \"INHERIT\" then __compute_context = \"&__global_compute_context\" ;\n      if __connection_name = \"INHERIT\" then __connection_name = \"&__global_connection_name\" ;\n      if __exec_log = \"INHERIT\" then __exec_log = \"&__global_exec_log\" ;\n      if __codegen_init_code = \"INHERIT\" then __codegen_init_code = \"&__global_codegen_init_code\" ;\n      if __codegen_wrap_code = \"INHERIT\" then __codegen_wrap_code = \"&__global_codegen_wrap_code\" ;\n      if __job_airflow_macrovars = \"INHERIT\" then __job_airflow_macrovars = \"&__global_job_airflow_macrovars\" ;\n      if __dag_parameters not in (\"\",\"INHERIT\") then do ;\n         length param $ 256 ;\n         param_dict_name=cats(__task_id,\"_params\") ;\n         put param_dict_name \"= {\" ;\n         c2=countw(__dag_parameters,\",\",\"q\") ;\n         do j=1 to c2 ;\n            param=strip(scan(__dag_parameters,j,\",\",\"q\")) ;\n            if j<c2 then put +3 param +(-1) \",\" ;\n            else put +3 param ;\n         end ;\n         put \"}\" ;\n         put ;\n      end ;\n      else if __dag_parameters = \"INHERIT\" and symget(\"__global_dag_parameters\") ne \"\" then param_dict_name=\"global_params\" ;\n      else param_dict_name=\"\" ;\n\n      if __dag_parameter_method = \"INHERIT\" then __dag_parameter_method = \"&__global_dag_parameter_method\" ;\n\n\n      if upcase(__task_type)=\"FILESENSOR\" then do ;\n         task_label=ifc(strip(__task_name) ne \"\",strip(__task_name),catx(\"_\",put(_n_,12.),\"wait_for_file\")) ;\n         fs_file=scan(__task_fs_file,2,\":\") ;\n         put __task_id +(-1) \" = FileSensor(task_id=\"\"\" task_label +(-1) \"\"\",\" ;\n         put \"   filepath=\"\"\" fs_file +(-1) \"\"\",\" ;\n         put \"   fs_conn_id=\"\"\" __task_fs_con_name +(-1) \"\"\",\" ;\n         put \"   poke_interval=\" __task_fs_poke +(-1) \",\" ;\n         put \"   timeout=\" __task_fs_timeout +(-1) \",\" ;\n         put \"   mode=\"\"\" __task_fs_mode +(-1) \"\"\",\" ;\n      end ;\n      else if object_type in (\"flow\",\"program\") then do ;   \n         put __task_id +(-1) \" = SASStudioOperator(task_id=\"\"\" task_label +(-1) \"\"\",\" ;\n         put \"   exec_type=\"\"\" object_type +(-1) \"\"\",\" ;\n         put \"   path_type=\"\"\" object_path_type +(-1) \"\"\",\" ;\n         if object_path_type=\"raw\" then \n            put \"   path=\" code_name +(-1) \",\" ;\n         else put \"   path=\"\"\" object_path +(-1) \"\"\",\" ;\n         if symget(\"__dag_optimization_method\") = \"SERIAL\"\n            then put \"   compute_session_id=\"\"{{ ti.xcom_pull(key='compute_session_id', task_ids=['0_create_session'])|first }}\"\",\" ;\n         put \"   compute_context=\"\"\" __compute_context +(-1) \"\"\",\" ;\n         put \"   connection_name=\"\"\" __connection_name +(-1) \"\"\",\" ;\n         put \"   exec_log=\" __exec_log +(-1) \",\" ;\n         put \"   codegen_init_code=\" __codegen_init_code +(-1) \",\" ;\n         put \"   codegen_wrap_code=\" __codegen_wrap_code +(-1) \",\" ;\n         if param_dict_name ne \"\" then do ;\n            if __dag_parameter_method in (\"MV\",\"BOTH\") then do ;\n               put \"   macro_vars=\" param_dict_name +(-1) \",\" ;\n            end ;\n            if __dag_parameter_method in (\"EV\",\"BOTH\") then do ;\n               put \"   env_vars=\" param_dict_name +(-1) \",\" ;\n            end ;\n         end ;\n      end ;\n      else if object_type=\"job\" then do ;   \n         put __task_id +(-1) \" = SASJobExecutionOperator(task_id=\"\"\" task_label +(-1) \"\"\",\" ;\n         put \"   job_name=\"\"\" object_path +(-1) \"\"\",\" ;\n         put \"   connection_name=\"\"\" __connection_name +(-1) \"\"\",\" ;\n         put \"   job_exec_log=\" __exec_log +(-1) \",\" ;\n         put \"   add_airflow_vars=\" __job_airflow_macrovars +(-1) \",\" ;\n         if param_dict_name ne \"\" then do ;\n            put \"   parameters=\" param_dict_name +(-1) \",\" ;\n         end ;\n         else put \"   parameters={},\" ;\n      end ;\n\n      if __task_datasets_produced ne \"\" then do ;\n         put +3 \"outlets=[\" @ ;\n         length ds $ 256 ;\n         c3=countw(__task_datasets_produced,\",\",\"q\") ;\n         do k=1 to c3 ;\n            ds=strip(scan(__task_datasets_produced,k,\",\",\"q\")) ;\n            if k<c3 then put \"Dataset(\"\"\" ds +(-1) \"\"\"),\" @ ;\n            else put \"Dataset(\"\"\" ds +(-1) \"\"\")\" @ ;\n         end ;\n         put \"],\" ;\n      end ;\n\n      put \"   trigger_rule='\" __task_trigger_rule +(-1) \"',\" ;\n\n      put \"   dag=dag)\" ;\n      put ;\n   \n   run ;\n   \n   /* If SERIAL, set __task0 as first step */\n   %if \"&__dag_optimization_method\" = \"SERIAL\" %then %do ;\n      data _null_ ;\n         file dag_file mod ;\n         set __dag__(where=(__task_predecessor_id=\"__INIT__\")) ;\n         put \"__task0 >> \" __task_id ;\n      run ;\n   %end ;\n\n   data _null_ ;\n      file dag_file mod ;\n      set __dag__(firstobs=2) ;\n      if __task_id ne \"__END__\" and __task_predecessor_id ne \"__INIT__\" then do ;\n         put __task_predecessor_id \">> \" __task_id ;\n      end ;\n   run ;\n\n   /* If SERIAL, set __task9999 as last step */\n   %if \"&__dag_optimization_method\" = \"SERIAL\" %then %do ;\n      data _null_ ;\n         file dag_file mod ;\n         set __dag__(where=(__task_id=\"__END__\")) ;\n         put __task_predecessor_id \">> __task9999\" ;\n      run ;\n   %end ;\n\n\n   /* Clean-up custom steps tables */\n\n   proc datasets lib=work nowarn noprint ;\n      delete __dag__ __distinct_tasks__ __task__ ;\n   quit ;\n\n%mend DAGend ;\n\n%DAGend ;\n"}}