{"creationTimeStamp":"2023-10-10T14:30:00.417Z","modifiedTimeStamp":"2023-10-12T20:51:15.214Z","createdBy":"Sundaresh.Sankaran@sas.com","modifiedBy":"Sundaresh.Sankaran@sas.com","name":"OCR - Azure AI Document Intelligence Table Extraction.step","displayName":"OCR - Azure AI Document Intelligence Table Extraction.step","localDisplayName":"OCR - Azure AI Document Intelligence Table Extraction.step","properties":{},"links":[{"method":"GET","rel":"self","href":"/dataFlows/steps/ff4e1b3c-88bb-4add-930b-70d89e1478b4","uri":"/dataFlows/steps/ff4e1b3c-88bb-4add-930b-70d89e1478b4","type":"application/vnd.sas.data.flow.step"},{"method":"GET","rel":"alternate","href":"/dataFlows/steps/ff4e1b3c-88bb-4add-930b-70d89e1478b4","uri":"/dataFlows/steps/ff4e1b3c-88bb-4add-930b-70d89e1478b4","type":"application/vnd.sas.data.flow.step.summary"},{"method":"GET","rel":"up","href":"/dataFlows/steps","uri":"/dataFlows/steps","type":"application/vnd.sas.collection","itemType":"application/vnd.sas.data.flow.step.summary"},{"method":"PUT","rel":"update","href":"/dataFlows/steps/ff4e1b3c-88bb-4add-930b-70d89e1478b4","uri":"/dataFlows/steps/ff4e1b3c-88bb-4add-930b-70d89e1478b4","type":"application/vnd.sas.data.flow.step","responseType":"application/vnd.sas.data.flow.step"},{"method":"DELETE","rel":"delete","href":"/dataFlows/steps/ff4e1b3c-88bb-4add-930b-70d89e1478b4","uri":"/dataFlows/steps/ff4e1b3c-88bb-4add-930b-70d89e1478b4"},{"method":"GET","rel":"transferExport","href":"/dataFlows/steps/ff4e1b3c-88bb-4add-930b-70d89e1478b4","uri":"/dataFlows/steps/ff4e1b3c-88bb-4add-930b-70d89e1478b4","responseType":"application/vnd.sas.transfer.object"},{"method":"PUT","rel":"transferImportUpdate","href":"/dataFlows/steps/ff4e1b3c-88bb-4add-930b-70d89e1478b4","uri":"/dataFlows/steps/ff4e1b3c-88bb-4add-930b-70d89e1478b4","type":"application/vnd.sas.transfer.object","responseType":"application/vnd.sas.summary"}],"metadataVersion":0.0,"version":2,"type":"code","flowMetadata":{"inputPorts":[],"outputPorts":[{"name":"outputListTable","displayName":"outputListTable","localDisplayName":"outputListTable","minEntries":0,"maxEntries":1,"defaultEntries":0,"type":"table","supportsView":false,"requiresStructure":false}]},"ui":"{\n\t\"showPageContentOnly\": true,\n\t\"pages\": [\n\t\t{\n\t\t\t\"id\": \"_nlp_ss_params\",\n\t\t\t\"type\": \"page\",\n\t\t\t\"label\": \"Parameters\",\n\t\t\t\"children\": [\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"section_inp_param\",\n\t\t\t\t\t\"type\": \"section\",\n\t\t\t\t\t\"label\": \"Input Parameters\",\n\t\t\t\t\t\"open\": true,\n\t\t\t\t\t\"visible\": \"\",\n\t\t\t\t\t\"children\": [\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"docUrl\",\n\t\t\t\t\t\t\t\"type\": \"textfield\",\n\t\t\t\t\t\t\t\"label\": \"Provide URL where document is located:\",\n\t\t\t\t\t\t\t\"placeholder\": \"https://a/path/to/my/pdf/or/image\",\n\t\t\t\t\t\t\t\"required\": true,\n\t\t\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t\t\t}\n\t\t\t\t\t]\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"section_op\",\n\t\t\t\t\t\"type\": \"section\",\n\t\t\t\t\t\"label\": \"Output specifications\",\n\t\t\t\t\t\"open\": true,\n\t\t\t\t\t\"visible\": \"\",\n\t\t\t\t\t\"children\": [\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"outputOption\",\n\t\t\t\t\t\t\t\"type\": \"dropdown\",\n\t\t\t\t\t\t\t\"label\": \"Select output destination for all tables: \",\n\t\t\t\t\t\t\t\"items\": [\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"value\": \"dataset\",\n\t\t\t\t\t\t\t\t\t\"label\": \"SAS Datasets\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"value\": \"json\",\n\t\t\t\t\t\t\t\t\t\"label\": \"JSON\"\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t],\n\t\t\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\t\t\"placeholder\": \"\",\n\t\t\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"infoForDSSelect\",\n\t\t\t\t\t\t\t\"type\": \"text\",\n\t\t\t\t\t\t\t\"text\": \"You've selected SAS datasets as the output destination. Please attach a SAS dataset to the output table port to capture a list of tables and columns extracted.\\n\\nThis also serves two other purposes:\\n1. Informs step on output libname to save datasets to\\n2. Acts as a name pattern\\n\\nFor example, if you provide WORK.OCREXTRACT, then all extracted tables will be saved as WORK.OCREXTRACT_1, WORK.OCREXTRACT_2..... WORK.OCREXTRACT_N.\",\n\t\t\t\t\t\t\t\"visible\": [\n\t\t\t\t\t\t\t\t\"$outputOption\",\n\t\t\t\t\t\t\t\t\"=\",\n\t\t\t\t\t\t\t\t\"dataset\"\n\t\t\t\t\t\t\t]\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"infoForJSONSelect\",\n\t\t\t\t\t\t\t\"type\": \"text\",\n\t\t\t\t\t\t\t\"text\": \"You've selected JSON as the output destination. Provide a name for your desired JSON file in a valid path on the filesystem.\",\n\t\t\t\t\t\t\t\"visible\": [\n\t\t\t\t\t\t\t\t\"$outputOption\",\n\t\t\t\t\t\t\t\t\"=\",\n\t\t\t\t\t\t\t\t\"json\"\n\t\t\t\t\t\t\t]\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"jsonFileName\",\n\t\t\t\t\t\t\t\"type\": \"path\",\n\t\t\t\t\t\t\t\"label\": \"Provide an output JSON filename\",\n\t\t\t\t\t\t\t\"pathtype\": \"file\",\n\t\t\t\t\t\t\t\"placeholder\": \"\",\n\t\t\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\t\t\"visible\": [\n\t\t\t\t\t\t\t\t\"$outputOption\",\n\t\t\t\t\t\t\t\t\"=\",\n\t\t\t\t\t\t\t\t\"json\"\n\t\t\t\t\t\t\t]\n\t\t\t\t\t\t}\n\t\t\t\t\t]\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"outputListTable\",\n\t\t\t\t\t\"type\": \"outputtable\",\n\t\t\t\t\t\"label\": \"Output list table:\",\n\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\"placeholder\": \"\",\n\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t}\n\t\t\t]\n\t\t},\n\t\t{\n\t\t\t\"id\": \"configuration\",\n\t\t\t\"type\": \"page\",\n\t\t\t\"label\": \"Configuration\",\n\t\t\t\"children\": [\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"docIntEndpoint\",\n\t\t\t\t\t\"type\": \"textfield\",\n\t\t\t\t\t\"label\": \"Provide Azure Document Intelligence endpoint: \",\n\t\t\t\t\t\"placeholder\": \"\",\n\t\t\t\t\t\"required\": true,\n\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"docIntKey\",\n\t\t\t\t\t\"type\": \"path\",\n\t\t\t\t\t\"label\": \"Attach a text file containing your Document Intelligence key:\",\n\t\t\t\t\t\"pathtype\": \"file\",\n\t\t\t\t\t\"placeholder\": \"/path/to/your/key\",\n\t\t\t\t\t\"required\": true,\n\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t}\n\t\t\t]\n\t\t},\n\t\t{\n\t\t\t\"id\": \"_nlp_ss_about\",\n\t\t\t\"type\": \"page\",\n\t\t\t\"label\": \"About\",\n\t\t\t\"children\": [\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"text_description\",\n\t\t\t\t\t\"type\": \"text\",\n\t\t\t\t\t\"text\": \"OCR - Azure AI Document Intelligence Table Extraction\\n=====================================================\\n\\nThis custom step extracts tables contained in PDFs and images using Microsoft Azure's Document Intelligence cloud AI services (formerly known as Form Recognizer).\\n\\nOrganizations require seamless extraction and analysis of structured tabular information embedded in document formats. Use this step to help tackle challenges that occur when dealing with data in document formats.\\n\\nNote that the Azure AI Document Intelligence service is capable of extracting other elements via OCR, all of which shall be gradually added to this custom step.\",\n\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"about_parameters\",\n\t\t\t\t\t\"type\": \"section\",\n\t\t\t\t\t\"label\": \"Parameters\",\n\t\t\t\t\t\"open\": false,\n\t\t\t\t\t\"visible\": \"\",\n\t\t\t\t\t\"children\": [\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"parameters_text\",\n\t\t\t\t\t\t\t\"type\": \"text\",\n\t\t\t\t\t\t\t\"text\": \"This custom step requires Python to be installed as it makes use of the Python client for Document Intelligence, as shown in the example at https://learn.microsoft.com/en-us/azure/ai-services/document-intelligence/quickstarts/get-started-sdks-rest-api?view=doc-intel-3.1.0&tabs=ga%2Cv2-0&pivots=programming-language-python.\\n\",\n\t\t\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"param_prereqs\",\n\t\t\t\t\t\t\t\"type\": \"section\",\n\t\t\t\t\t\t\t\"label\": \"Prerequisites\",\n\t\t\t\t\t\t\t\"open\": true,\n\t\t\t\t\t\t\t\"visible\": \"\",\n\t\t\t\t\t\t\t\"children\": [\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"id\": \"text1\",\n\t\t\t\t\t\t\t\t\t\"type\": \"text\",\n\t\t\t\t\t\t\t\t\t\"text\": \"1. Python (version 3.7 or later) installed and accessible to proc python within SAS Viya.\\n\\n2. The following Python packages need to be installed.  Note that version numbers where specified may be subject to change as per Azure.\\n\\n   - azure-ai-formrecognizer==3.3.0 \\n   - azure-core \\n   - pandas\\n\\n2. Preferable / recommended:  Make use of the SAS Configurator for Open Source (also commonly known as sas-pyconfig) to install and configure Python access from SAS Viya.  Refer SAS Viya Deployment Guide (monthly stable 2023.08 onwards) for instructions on the same. Documentation provided below.\\n\\n3. An Azure subscription and an active Azure AI Services or Document Intelligence  resource.  You can create the same through an Azure portal or CLI.\\n\\n4. Once your resource is ready, retrieve your Azure endpoint and access key for use within the UI.\\n\",\n\t\t\t\t\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t]\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"parameters_input\",\n\t\t\t\t\t\t\t\"type\": \"section\",\n\t\t\t\t\t\t\t\"label\": \"Input Parameters\",\n\t\t\t\t\t\t\t\"open\": true,\n\t\t\t\t\t\t\t\"visible\": \"\",\n\t\t\t\t\t\t\t\"children\": [\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"id\": \"input_parameters_text\",\n\t\t\t\t\t\t\t\t\t\"type\": \"text\",\n\t\t\t\t\t\t\t\t\t\"text\": \"- Document URL (text field, required): provide a path to a URL where your document resides.  The document could be either a PDF or an image format as allowed by Azure.  Refer the Azure quickstart (as mentioned in documentation) for any additional details on the types of documents.\\n\\nNote that ALL table elements identified in the document will be extracted as a single call. You may choose to filter tables to keep downstream.\",\n\t\t\t\t\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t]\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"parameters_output_specs\",\n\t\t\t\t\t\t\t\"type\": \"section\",\n\t\t\t\t\t\t\t\"label\": \"Output Specifications\",\n\t\t\t\t\t\t\t\"open\": true,\n\t\t\t\t\t\t\t\"visible\": \"\",\n\t\t\t\t\t\t\t\"children\": [\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"id\": \"output_parameters_text\",\n\t\t\t\t\t\t\t\t\t\"type\": \"text\",\n\t\t\t\t\t\t\t\t\t\"text\": \"1. Select output table destination (drop-down list, SAS Dataset is the default): choose between outputting your table extracts to SAS datasets or JSON files as per your desired process\\n\\n2. Output list table (output port, optional): in case you have selected SAS Datasets, provide an output table to this port.  As noted on the UI, this table holds information on the extracts, not the actual extract. For potentially multiple tables extracted, this also serves as a name pattern.\\n\\n2.a.  Select a name that's short and can serve as a pattern.  For example, a name of WORK.OCREXTRACT leads to multiple exracted tables written to WORK.OCREXTRACT_1, WORK.OCREXTRACT_2, .... WORK.OCREXTRACT_<N>, depending on the number of tables in the document.\\n\\n2.b.  Note that the location (libname) of this table serves as the destination of the extracted tables themselves\\n\\n3. JSON file (file selector, optional): in case you've selected JSON as the output destination, provide a valid path to a JSON file which will hold the results of the extracts.\\n\",\n\t\t\t\t\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t]\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"parameters_config\",\n\t\t\t\t\t\t\t\"type\": \"section\",\n\t\t\t\t\t\t\t\"label\": \"Configuration (tab)\",\n\t\t\t\t\t\t\t\"open\": true,\n\t\t\t\t\t\t\t\"visible\": \"\",\n\t\t\t\t\t\t\t\"children\": [\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"id\": \"input_parameters_text_1\",\n\t\t\t\t\t\t\t\t\t\"type\": \"text\",\n\t\t\t\t\t\t\t\t\t\"text\": \"1. Path to a file containing your Document Intelligence key (file selector, required): save your key in a secure location (i.e. accessible only to designated persons) and provide this path \\n\\n2. Azure Document Intelligence endpoint (text field, required): refer to the Microsoft Azure resource you had created to obtain this value\",\n\t\t\t\t\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t]\n\t\t\t\t\t\t}\n\t\t\t\t\t]\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"about_runtimecontrol\",\n\t\t\t\t\t\"type\": \"section\",\n\t\t\t\t\t\"label\": \"Run-time Control\",\n\t\t\t\t\t\"open\": false,\n\t\t\t\t\t\"visible\": \"\",\n\t\t\t\t\t\"children\": [\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"runtimecontrol_text\",\n\t\t\t\t\t\t\t\"type\": \"text\",\n\t\t\t\t\t\t\t\"text\": \"Note: Run-time control is optional.  You may choose whether to execute the main code of this step or not, based on upstream conditions set by earlier SAS programs.  This includes nodes run prior to this custom step earlier in a SAS Studio Flow, or a previous program in the same session.\\n\\nRefer this blog (https://communities.sas.com/t5/SAS-Communities-Library/Switch-on-switch-off-run-time-control-of-SAS-Studio-Custom-Steps/ta-p/885526) for more details on the concept.\\n\\nThe following macro variable,\\n\\n_eto_run_trigger\\n\\nwill initialize with a value of 1 by default, indicating an \\\"enabled\\\" status and allowing the custom step to run.\\n\\nIf you wish to control execution of this custom step, include code in an upstream SAS program to set this variable to 0.  This \\\"disables\\\" execution of the custom step.\\n\\nTo \\\"disable\\\" this step, run the following code upstream:\\n\\n%global _eto_run_trigger;\\n%let _eto_run_trigger =0;\\n\\nTo \\\"enable\\\" this step again, run the following (it's assumed that this has already been set as a global variable):\\n\\n%let _eto_run_trigger =1;\\n\\nIMPORTANT: Be aware that disabling this step means that none of its main execution code will run, and any  downstream code which was dependent on this code may fail.  Change this setting only if it aligns with the objective of your SAS Studio program.\",\n\t\t\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t\t\t}\n\t\t\t\t\t]\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"about_documentation\",\n\t\t\t\t\t\"type\": \"section\",\n\t\t\t\t\t\"label\": \"Documentation\",\n\t\t\t\t\t\"open\": false,\n\t\t\t\t\t\"visible\": \"\",\n\t\t\t\t\t\"children\": [\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"documentation_text\",\n\t\t\t\t\t\t\t\"type\": \"text\",\n\t\t\t\t\t\t\t\"text\": \"1. Azure example for accessing the Document Intelligence via Python: https://learn.microsoft.com/en-us/azure/ai-services/document-intelligence/quickstarts/get-started-sdks-rest-api?view=doc-intel-3.1.0&tabs=ga%2Cv2-0&pivots=programming-language-python\\n\\n2. A general article / blog on Azure AI Document Intelligence (previously known as Form Recognizer): https://techcommunity.microsoft.com/t5/azure-ai-services-blog/enhanced-table-extraction-from-documents-with-form-recognizer/ba-p/2058011\\n\\n3. Scott McCauley's article on configuring Viya for Python integration: https://communities.sas.com/t5/SAS-Communities-Library/Configuring-SAS-Viya-for-Python-Integration/ta-p/847459\\n\\n4. The SAS Viya Platform Deployment Guide (refer to SAS Configurator for Open Source within): https://go.documentation.sas.com/doc/en/itopscdc/default/itopssr/p1n66p7u2cm8fjn13yeggzbxcqqg.htm?fromDefault=#p19cpvrrjw3lurn135ih46tjm7oi \",\n\t\t\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t\t\t}\n\t\t\t\t\t]\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"change_log_text\",\n\t\t\t\t\t\"type\": \"text\",\n\t\t\t\t\t\"text\": \"Version: 1.0  (02JAN2024)\",\n\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"contact_text\",\n\t\t\t\t\t\"type\": \"text\",\n\t\t\t\t\t\"text\": \"Created/contact: \\n\\n- Sundaresh Sankaran (sundaresh.sankaran@sas.com)\\n\",\n\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t}\n\t\t\t]\n\t\t}\n\t],\n\t\"syntaxversion\": \"1.3.0\",\n\t\"values\": {\n\t\t\"docUrl\": \"\",\n\t\t\"outputOption\": {\n\t\t\t\"value\": \"dataset\",\n\t\t\t\"label\": \"SAS Datasets\"\n\t\t},\n\t\t\"jsonFileName\": \"\",\n\t\t\"outputListTable\": {\n\t\t\t\"library\": \"\",\n\t\t\t\"table\": \"\"\n\t\t},\n\t\t\"docIntEndpoint\": \"\",\n\t\t\"docIntKey\": \"\"\n\t}\n}","templates":{"SAS":"/* SAS templated code goes here */\n/*-----------------------------------------------------------------------------------------*\n   START MACRO DEFINITIONS.\n*------------------------------------------------------------------------------------------*/\n\n/* -----------------------------------------------------------------------------------------* \n   Error flag for capture during code execution.\n*------------------------------------------------------------------------------------------ */\n\n%global _eto_error_flag;\n%let _eto_error_flag=0;\n\n/* -----------------------------------------------------------------------------------------* \n   Global macro variable for the trigger to run this custom step. A value of 1 \n   (the default) enables this custom step to run.  A value of 0 (provided by upstream code)\n   sets this to disabled.\n*------------------------------------------------------------------------------------------ */\n\n%global _eto_run_trigger;\n\n%if %sysevalf(%superq(_eto_run_trigger)=, boolean)  %then %do;\n\n\t%put NOTE: Trigger macro variable _eto_run_trigger does not exist. Creating it now.;\n    %let _eto_run_trigger=1;\n\n%end;\n\n/* -----------------------------------------------------------------------------------------* \n   Create a macro variable which contains the location of the key file.\n*------------------------------------------------------------------------------------------ */\n\ndata _null_;\n   call symput(\"docIntKeyLoc\", scan(\"&docIntKey.\",2,\":\",\"MO\"));\nrun;\n\n/* -----------------------------------------------------------------------------------------* \n   Read the key contents into a macro variable\n*------------------------------------------------------------------------------------------ */\n\ndata _null_;\nlength text $10000.;\ninfile \"&docIntKeyLoc.\" lrecl=10000 ;\ninput @1 text $;\ncall symput(\"docIntKeyValue\",text);\nrun;\n\n/* -----------------------------------------------------------------------------------------* \n   Create a macro variable which contains the location of the JSON file.\n*------------------------------------------------------------------------------------------ */\n\ndata _null_;\n   call symput(\"jsonFilePath\", scan(\"&jsonFileName.\",2,\":\",\"MO\"));\nrun;\n\n\n\n/*-----------------------------------------------------------------------------------------*\n   FUTURE PLACEHOLDER: EXECUTION CODE MACRO \n   NOTE: Execution code needs (proc python) submit blocks to be converted to infiles for \n         running within a macro.  Placeholder to undertake this in future.\n*------------------------------------------------------------------------------------------*/\n%macro main_execution_code;\n%mend main_execution_code;\n\n\n/*-----------------------------------------------------------------------------------------*\n   END OF MACROS\n*------------------------------------------------------------------------------------------*/\n\n\n/*-----------------------------------------------------------------------------------------*\n   EXECUTION CODE\n   Note: Python code blocks follow different indentation logic and are currently not\n   indented within the SAS proc python blocks below. Comments may not be rendered as \n   elegantly as SAS code.\n*------------------------------------------------------------------------------------------*/\n\n\nproc python;\n\nsubmit;\n\n#############################################################################################\n#\n#  Imports\n#\n#############################################################################################\n\nimport os\nfrom azure.ai.formrecognizer import DocumentAnalysisClient\nfrom azure.core.credentials import AzureKeyCredential\nimport pandas as pd\nimport json\n\n#############################################################################################\n#\n#  Helper functions (code adapted from Quickstart guide of MS Azure)\n#  located at \n#  https://learn.microsoft.com/en-us/azure/ai-services/document-intelligence/quickstarts/get-started-sdks-rest-api?pivots=programming-language-python\n# \n#############################################################################################\n\ndef format_polygon(polygon):\n    if not polygon:\n        return \"N/A\"\n    return \", \".join([\"[{}, {}]\".format(p.x, p.y) for p in polygon])\n\n\ndef analyze_general_documents(docUrl):    \n#############################################################################################\n#\n#  Create a document analysis client\n#\n#############################################################################################\n    document_analysis_client = DocumentAnalysisClient(endpoint=endpoint, credential=AzureKeyCredential(key))\n#############################################################################################\n#\n#  FOR USER CUSTOMIZATION CONSIDERATION: You may choose to swap out the prebuilt-document  \n#  template with a custom model after going through Azure references and documentation\n#\n#############################################################################################\n    poller = document_analysis_client.begin_analyze_document_from_url(\n            \"prebuilt-document\", docUrl)\n    result = poller.result()\n#############################################################################################\n#\n#  Table processing activities follow  Future placeholder: additional helper functions for\n#  handling other extracted elements, for example, raw text, selection marks etc \n#\n#############################################################################################\n    for table_idx, table in enumerate(result.tables):\n        print(\n            \"Table # {} has {} rows and {} columns\".format(\n                table_idx, table.row_count, table.column_count\n            )\n        )\n        for region in table.bounding_regions:\n            print(\n                \"Table # {} location on page: {} is {}\".format(\n                    table_idx,\n                    region.page_number,\n                    format_polygon(region.polygon),\n                )\n            )  \n    return result.tables\n\n#############################################################################################\n#\n#  Obtain docUrl, endpoint and key from UI\n#\n#############################################################################################\n\n_eto_error_flag   = SAS.symget(\"_eto_error_flag\")\ndocUrl            = SAS.symget(\"docUrl\")\nendpoint          = SAS.symget(\"docIntEndpoint\")\nkey               = SAS.symget(\"docIntKeyValue\")\n_eto_run_trigger  = SAS.symget(\"_eto_run_trigger\")\noutput_option     = SAS.symget(\"outputOption\")\njson_file_path    = SAS.symget(\"jsonFilePath\")\noutput_table_lib  = SAS.symget(\"outputListTable_lib\")\noutput_table_name = SAS.symget(\"outputListTable_name\")\noutput_table      = SAS.symget(\"outputListTable\")\n\n#############################################################################################\n#\n#  Error check: has an output dataset been provided in case of dataset being selected?\n#\n#############################################################################################\n\nif output_option == \"dataset\":\n   if not output_table:\n      SAS.logMessage(\"Check if you've provided a valid output table.\",\"ERROR\")\n      _eto_error_flag = 1\n\n#############################################################################################\n#\n#  Error check: has a JSON file been provided in case of JSON being selected?\n#\n#############################################################################################\n\nif output_option == \"json\":\n   if not json_file_path:\n      SAS.logMessage(\"Check if you've provided a valid path to a JSON file.\",\"ERROR\")\n      _eto_error_flag = 1\n\n#############################################################################################\n#\n#  Error check: has a key velue been provided?\n#\n#############################################################################################\n\nif not key:\n   SAS.logMessage(\"Key value seems empty, check contents of key file.\",\"ERROR\")\n   _eto_error_flag = 1\n\n#############################################################################################\n#\n#  Error check: has the endpoint been provided?\n#\n#############################################################################################\n\nif not endpoint:\n   SAS.logMessage(\"Provide an active Azure Document Intelligence resource endpoint.\",\"ERROR\")\n   _eto_error_flag = 1\n\n#############################################################################################\n#\n#  Run main extraction, conditional upon the run-time trigger\n#\n#############################################################################################\n\nif int(_eto_run_trigger) == 1  and int(_eto_error_flag) == 0:\n   table_result = analyze_general_documents(docUrl)\n\n#############################################################################################\n#\n#  Process output to make it easier to transfer to downstream tasks\n#\n#############################################################################################\nif table_result:\n   all_tables = []\n   for idx, atable in enumerate(table_result):\n      row_count = atable.row_count\n      column_count = atable.column_count\n#############################################################################################\n#\n#  Create an empty array of the same shape as table \n#  Future placeholder: create the same in an elegant way without loops\n#\n#############################################################################################\n      darray=[]\n      for row in range(row_count):\n        carray=[]\n        for col in range(column_count):\n           carray.append(\"\")\n        darray.append(carray)\n#############################################################################################\n#\n#  Populate array with specific indices output from cell results\n#\n#############################################################################################\n      for eachcell in atable.cells:\n         darray[eachcell.row_index][eachcell.column_index]=eachcell.content\n#############################################################################################\n#\n#  Convert to Pandas DataFrame and add to final result array\n#\n#############################################################################################\n      pdf = pd.DataFrame(darray)\n      all_tables.append(pdf.to_dict(orient='list'))\n#############################################################################################\n#\n#  For cases where the user chooses to output to SAS dataset, carry out the conversion for \n#  each dataframe one by one\n#\n#############################################################################################\n      SAS.df2sd(pdf, dataset=\"{}.{}_{}\".format(output_table_lib,output_table_name,str(idx)))\n#############################################################################################\n#\n#  For cases where the user chooses to output to JSON, write the entire list of dictionaries \n#  to a JSON file\n#\n#  Customization consideration: You may choose to write additional code harnessing SAS JSON\n#  libname engine to read the JSON file as an alternative data transfer mechanism\n#\n#############################################################################################\n   if output_option == \"json\":\n      with open(json_file_path,\"w\") as jsonfile:\n         json.dump(all_tables,jsonfile)\n\nSAS.symput(\"_eto_error_flag\", _eto_error_flag)\n\nendsubmit;\nquit;\n\n/*-----------------------------------------------------------------------------------------*\n   Create a summary table of all extracts\n*------------------------------------------------------------------------------------------*/\n%if &_eto_error_flag. = 0 %then %do;\n   proc datasets noprint;\n      contents data=_all_ out=&outputListTable.;\n   quit;\n%end;\n\n\n/*-----------------------------------------------------------------------------------------*\n   Clean up existing macro variables and macro definitions.\n*------------------------------------------------------------------------------------------*/\n%sysmacdelete main_execution_code;\n%symdel _eto_run_trigger;\n%symdel docIntKeyLoc ;\n%symdel docIntKeyValue ;\n%symdel jsonFilePath ;\n%symdel _eto_error_flag;\n\n"}}